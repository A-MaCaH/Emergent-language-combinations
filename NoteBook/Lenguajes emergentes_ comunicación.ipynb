{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPVx9nCDyfBH0tdeF18nnjH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e43d4bd1a5a34cc5a3c0322c0cea7a6c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cd7e713d89e04116952a537ab5aea3f2","IPY_MODEL_8ee207bbbc314b55bbcf56c135106fef","IPY_MODEL_4efb059c10b74617862db3dfd11b1c9f"],"layout":"IPY_MODEL_362fb74126cf4824abe1b430dcbd9977"}},"cd7e713d89e04116952a537ab5aea3f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f88c62a7a69643aea2a5219ae032d0da","placeholder":"​","style":"IPY_MODEL_35527e77ba8a4081875213067f05dd7a","value":"tokenizer_config.json: 100%"}},"8ee207bbbc314b55bbcf56c135106fef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9f332c9487c4f42879f3a6cc4daa264","max":1289,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd9a01943ea6409399dbeaf9b9d47677","value":1289}},"4efb059c10b74617862db3dfd11b1c9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_597ea38b6b8d4df89f58fcde4cc05514","placeholder":"​","style":"IPY_MODEL_5731e1ce713b4c2fadc9eef9bb2bdf90","value":" 1.29k/1.29k [00:00&lt;00:00, 63.5kB/s]"}},"362fb74126cf4824abe1b430dcbd9977":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f88c62a7a69643aea2a5219ae032d0da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35527e77ba8a4081875213067f05dd7a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9f332c9487c4f42879f3a6cc4daa264":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd9a01943ea6409399dbeaf9b9d47677":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"597ea38b6b8d4df89f58fcde4cc05514":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5731e1ce713b4c2fadc9eef9bb2bdf90":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df066e378da04e079dfe4a35e4fea2b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f699a75a208743bd9bc9ec979eda951a","IPY_MODEL_ea0a4b4471e14096ab1af7db944c5e7e","IPY_MODEL_7bb4e9ea18fb4a49989fd8ee5f6c0629"],"layout":"IPY_MODEL_93ebe5e8405e447f997912edbaf557ad"}},"f699a75a208743bd9bc9ec979eda951a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a400a8b608346bcb4cb969411dc1ea3","placeholder":"​","style":"IPY_MODEL_ceedcc1f559541f484ac828f5774f829","value":"tokenizer.model: 100%"}},"ea0a4b4471e14096ab1af7db944c5e7e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_50ad23f3188b4109b58f9c9556a82b98","max":499723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1479efeb44234a3bab144ca0340a14df","value":499723}},"7bb4e9ea18fb4a49989fd8ee5f6c0629":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7a231f2189542ceb542ba57576c268d","placeholder":"​","style":"IPY_MODEL_341a7d1b2b25499babe1ef3b49716cf7","value":" 500k/500k [00:00&lt;00:00, 3.31MB/s]"}},"93ebe5e8405e447f997912edbaf557ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a400a8b608346bcb4cb969411dc1ea3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ceedcc1f559541f484ac828f5774f829":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50ad23f3188b4109b58f9c9556a82b98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1479efeb44234a3bab144ca0340a14df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b7a231f2189542ceb542ba57576c268d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"341a7d1b2b25499babe1ef3b49716cf7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c16bab710a874dc4b300f3563573c104":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c939e59b5de74230a18bff6bc4f1a498","IPY_MODEL_50cb95086d794affbbabefa4fd0910ac","IPY_MODEL_669ef4b52336483b90a5e595fd91d2c4"],"layout":"IPY_MODEL_11606f19947d4cb48a0bf9c153ead90b"}},"c939e59b5de74230a18bff6bc4f1a498":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e64d3ca440a4bc2b99049685d039d9c","placeholder":"​","style":"IPY_MODEL_abc76edaab684eb99bda1d809dd5e0f6","value":"tokenizer.json: 100%"}},"50cb95086d794affbbabefa4fd0910ac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_937dc66f4f85402599cfa67b23443dee","max":1842767,"min":0,"orientation":"horizontal","style":"IPY_MODEL_614bcc87ef8441089cc0992e9d0a3a01","value":1842767}},"669ef4b52336483b90a5e595fd91d2c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d40fe870dbf4444fb28768c0c69aac56","placeholder":"​","style":"IPY_MODEL_0418effdb5ba499f870f5a566778b43f","value":" 1.84M/1.84M [00:00&lt;00:00, 2.65MB/s]"}},"11606f19947d4cb48a0bf9c153ead90b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e64d3ca440a4bc2b99049685d039d9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abc76edaab684eb99bda1d809dd5e0f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"937dc66f4f85402599cfa67b23443dee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"614bcc87ef8441089cc0992e9d0a3a01":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d40fe870dbf4444fb28768c0c69aac56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0418effdb5ba499f870f5a566778b43f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bcee996b9655449b8b39b922bc5d95e1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d680ebe3f91144938dab67ee09f97f08","IPY_MODEL_1fbe785de9824decb70f450adfb01e77","IPY_MODEL_eb2e46ec32c84c0d9b055b4ec239ecd0"],"layout":"IPY_MODEL_974ff4c7462f46b78bcdafc815d7c3e5"}},"d680ebe3f91144938dab67ee09f97f08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab083f7b55854932a82c9e9b36ab71f0","placeholder":"​","style":"IPY_MODEL_252d35466e9547899333174373109945","value":"special_tokens_map.json: 100%"}},"1fbe785de9824decb70f450adfb01e77":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_651e1020c2b8475f972bf0e1adefe01a","max":551,"min":0,"orientation":"horizontal","style":"IPY_MODEL_70372f450f3642fba8b52795f8184717","value":551}},"eb2e46ec32c84c0d9b055b4ec239ecd0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a603e647f814c34ae162e297c3a8d50","placeholder":"​","style":"IPY_MODEL_4e19c3dd07024f80994adeb8c55845e8","value":" 551/551 [00:00&lt;00:00, 13.4kB/s]"}},"974ff4c7462f46b78bcdafc815d7c3e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab083f7b55854932a82c9e9b36ab71f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"252d35466e9547899333174373109945":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"651e1020c2b8475f972bf0e1adefe01a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70372f450f3642fba8b52795f8184717":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0a603e647f814c34ae162e297c3a8d50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e19c3dd07024f80994adeb8c55845e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T0gbTr84GDE7","executionInfo":{"status":"ok","timestamp":1739314883060,"user_tz":360,"elapsed":21192,"user":{"displayName":"Alan Mauricio Camargo Hernandez","userId":"09753390928466343821"}},"outputId":"985ef3bb-f5b2-4f06-973f-10fe5e1e31e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 5/50, Loss: 1.0958\n","Epoch 10/50, Loss: 1.0913\n","Epoch 15/50, Loss: 1.0650\n","Epoch 20/50, Loss: 1.0518\n","Epoch 25/50, Loss: 1.0616\n","Epoch 30/50, Loss: 0.9078\n","Epoch 35/50, Loss: 0.8388\n","Epoch 40/50, Loss: 0.6474\n","Epoch 45/50, Loss: 0.6596\n","Epoch 50/50, Loss: 0.4725\n","\n","Generated Language (Messages for each state):\n","State 0: Message [0.1748702 0.6528762 0.8297448]\n","State 1: Message [0.01477792 0.03889632 0.9646633 ]\n","State 2: Message [0.9719188  0.98040956 0.09841765]\n","\n","Receiver's Actions for each Message:\n","State 0: Predicted Action 0, Correct Action 0\n","State 1: Predicted Action 1, Correct Action 1\n","State 2: Predicted Action 2, Correct Action 2\n","\n","Receiver Accuracy: 100.00%\n"]}],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import random\n","\n","# Hyperparameters\n","NUM_EPOCHS = 50\n","LEARNING_RATE = 0.01\n","MESSAGE_SIZE = 3\n","STATE_SIZE = 3\n","ACTION_SIZE = 3\n","HIDDEN_SIZE = 16\n","BATCH_SIZE = 32\n","\n","# Generate synthetic data: states and corresponding correct actions\n","states = torch.eye(STATE_SIZE)\n","correct_actions = torch.arange(ACTION_SIZE)\n","\n","def get_batch(batch_size):\n","    indices = random.choices(range(STATE_SIZE), k=batch_size)\n","    return states[indices], correct_actions[indices]\n","\n","# Neural network models for the agents\n","class Sender(nn.Module):\n","    def __init__(self, state_size, hidden_size, message_size):\n","        super(Sender, self).__init__()\n","        self.fc1 = nn.Linear(state_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, message_size)\n","\n","    def forward(self, state):\n","        hidden = torch.relu(self.fc1(state))\n","        message = torch.sigmoid(self.fc2(hidden))  # Message bounded between 0 and 1\n","        return message\n","\n","class Receiver(nn.Module):\n","    def __init__(self, message_size, hidden_size, action_size):\n","        super(Receiver, self).__init__()\n","        self.fc1 = nn.Linear(message_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, action_size)\n","\n","    def forward(self, message):\n","        hidden = torch.relu(self.fc1(message))\n","        action_logits = self.fc2(hidden)\n","        return action_logits\n","\n","# Initialize models, loss function, and optimizers\n","sender = Sender(STATE_SIZE, HIDDEN_SIZE, MESSAGE_SIZE)\n","receiver = Receiver(MESSAGE_SIZE, HIDDEN_SIZE, ACTION_SIZE)\n","\n","criterion = nn.CrossEntropyLoss()\n","sender_optimizer = optim.Adam(sender.parameters(), lr=LEARNING_RATE)\n","receiver_optimizer = optim.Adam(receiver.parameters(), lr=LEARNING_RATE)\n","\n","# Training loop\n","for epoch in range(NUM_EPOCHS):\n","    sender_optimizer.zero_grad()\n","    receiver_optimizer.zero_grad()\n","\n","    # Generate a batch of data\n","    state_batch, action_batch = get_batch(BATCH_SIZE)\n","\n","    # Forward pass\n","    messages = sender(state_batch)\n","    action_logits = receiver(messages)\n","\n","    # Compute loss\n","    loss = criterion(action_logits, action_batch)\n","\n","    # Backward pass and optimization\n","    loss.backward()\n","    sender_optimizer.step()\n","    receiver_optimizer.step()\n","\n","    # Print progress every 500 epochs\n","    if (epoch + 1) % 5 == 0:\n","        print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Loss: {loss.item():.4f}\")\n","\n","# Analyze the language generated by the Sender\n","print(\"\\nGenerated Language (Messages for each state):\")\n","for i, state in enumerate(states):\n","    with torch.no_grad():\n","        message = sender(state.unsqueeze(0)).squeeze(0)\n","        print(f\"State {i}: Message {message.numpy()}\")\n","\n","# Test the Receiver's performance\n","print(\"\\nReceiver's Actions for each Message:\")\n","correct = 0\n","for i, state in enumerate(states):\n","    with torch.no_grad():\n","        message = sender(state.unsqueeze(0))\n","        action_logits = receiver(message)\n","        action = torch.argmax(action_logits, dim=1).item()\n","        print(f\"State {i}: Predicted Action {action}, Correct Action {correct_actions[i].item()}\")\n","        if action == correct_actions[i].item():\n","            correct += 1\n","\n","accuracy = correct / STATE_SIZE\n","print(f\"\\nReceiver Accuracy: {accuracy * 100:.2f}%\")\n"]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import random\n","\n","# Hyperparameters\n","NUM_EPOCHS = 5000\n","LEARNING_RATE = 0.01\n","MESSAGE_SIZE = 1  # Message is now a single scalar value\n","STATE_SIZE = 5\n","ACTION_SIZE = 5\n","HIDDEN_SIZE = 16\n","BATCH_SIZE = 32\n","\n","# Generate synthetic data: states and corresponding correct actions\n","states = torch.eye(STATE_SIZE)\n","correct_actions = torch.arange(ACTION_SIZE)\n","\n","def get_batch(batch_size):\n","    indices = random.choices(range(STATE_SIZE), k=batch_size)\n","    return states[indices], correct_actions[indices]\n","\n","# Neural network models for the agents\n","class Sender(nn.Module):\n","    def __init__(self, state_size, hidden_size, message_size):\n","        super(Sender, self).__init__()\n","        self.fc1 = nn.Linear(state_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, message_size)\n","\n","    def forward(self, state):\n","        hidden = torch.relu(self.fc1(state))\n","        message = torch.sigmoid(self.fc2(hidden))  # Message bounded between 0 and 1\n","        return message\n","\n","class Receiver(nn.Module):\n","    def __init__(self, message_size, hidden_size, action_size):\n","        super(Receiver, self).__init__()\n","        self.fc1 = nn.Linear(message_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, action_size)\n","\n","    def forward(self, message):\n","        hidden = torch.relu(self.fc1(message))\n","        action_logits = self.fc2(hidden)\n","        return action_logits\n","\n","# Initialize models, loss function, and optimizers\n","sender = Sender(STATE_SIZE, HIDDEN_SIZE, MESSAGE_SIZE)\n","receiver = Receiver(MESSAGE_SIZE, HIDDEN_SIZE, ACTION_SIZE)\n","\n","criterion = nn.CrossEntropyLoss()\n","sender_optimizer = optim.Adam(sender.parameters(), lr=LEARNING_RATE)\n","receiver_optimizer = optim.Adam(receiver.parameters(), lr=LEARNING_RATE)\n","\n","# Training loop\n","for epoch in range(NUM_EPOCHS):\n","    sender_optimizer.zero_grad()\n","    receiver_optimizer.zero_grad()\n","\n","    # Generate a batch of data\n","    state_batch, action_batch = get_batch(BATCH_SIZE)\n","\n","    # Forward pass\n","    messages = sender(state_batch)\n","    action_logits = receiver(messages)\n","\n","    # Compute loss\n","    loss = criterion(action_logits, action_batch)\n","\n","    # Backward pass and optimization\n","    loss.backward()\n","    sender_optimizer.step()\n","    receiver_optimizer.step()\n","\n","    # Logging\n","    if (epoch + 1) % 500 == 0:\n","        print(f\"Epoch [{epoch + 1}/{NUM_EPOCHS}], Loss: {loss.item():.4f}\")\n","\n","# Inspect the learned messages and evaluate the system\n","print(\"Learned messages:\")\n","for i in range(STATE_SIZE):\n","    state = states[i].unsqueeze(0)  # Add batch dimension\n","    message = sender(state).detach().numpy()\n","    print(f\"State: {state.numpy()}, Message: {message}\")\n","\n","correct = 0\n","for i in range(STATE_SIZE):\n","    state = states[i].unsqueeze(0)\n","    message = sender(state)\n","    action_logits = receiver(message)\n","    predicted_action = action_logits.argmax(dim=1).item()\n","    if predicted_action == correct_actions[i].item():\n","        correct += 1\n","accuracy = correct / STATE_SIZE\n","print(f\"Final accuracy: {accuracy * 100:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EYWHhAUcKS9Q","executionInfo":{"status":"ok","timestamp":1737300481423,"user_tz":360,"elapsed":8374,"user":{"displayName":"Alan Mauricio Camargo Hernandez","userId":"09753390928466343821"}},"outputId":"bb7efb0b-2709-4999-b6e5-445f90c17686"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [500/5000], Loss: 0.3967\n","Epoch [1000/5000], Loss: 0.0100\n","Epoch [1500/5000], Loss: 0.0033\n","Epoch [2000/5000], Loss: 0.0015\n","Epoch [2500/5000], Loss: 0.0010\n","Epoch [3000/5000], Loss: 0.0006\n","Epoch [3500/5000], Loss: 0.0004\n","Epoch [4000/5000], Loss: 0.0002\n","Epoch [4500/5000], Loss: 0.0002\n","Epoch [5000/5000], Loss: 0.0001\n","Learned messages:\n","State: [[1. 0. 0. 0. 0.]], Message: [[0.44974348]]\n","State: [[0. 1. 0. 0. 0.]], Message: [[0.6985548]]\n","State: [[0. 0. 1. 0. 0.]], Message: [[0.20299342]]\n","State: [[0. 0. 0. 1. 0.]], Message: [[0.9998623]]\n","State: [[0. 0. 0. 0. 1.]], Message: [[5.348929e-05]]\n","Final accuracy: 100.00%\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import random\n","\n","# Hyperparameters\n","NUM_EPOCHS = 5000\n","LEARNING_RATE = 0.01\n","MESSAGE_SIZE = 1  # Message is now a single scalar value\n","STATE_SIZE = 3\n","ACTION_SIZE = 3\n","HIDDEN_SIZE = 16\n","BATCH_SIZE = 32\n","\n","# Generate synthetic data: states and corresponding correct actions\n","states = torch.eye(STATE_SIZE)\n","correct_actions = torch.arange(ACTION_SIZE)\n","\n","def get_batch(batch_size):\n","    indices = random.choices(range(STATE_SIZE), k=batch_size)\n","    return states[indices], correct_actions[indices]\n","\n","# Neural network models for the agents\n","class Sender(nn.Module):\n","    def __init__(self, state_size, hidden_size, message_size):\n","        super(Sender, self).__init__()\n","        self.fc1 = nn.Linear(state_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, message_size)\n","\n","    def forward(self, state):\n","        hidden = torch.relu(self.fc1(state))\n","        message = torch.sigmoid(self.fc2(hidden))  # Message bounded between 0 and 1\n","        return message\n","\n","class Receiver(nn.Module):\n","    def __init__(self, message_size, hidden_size, action_size):\n","        super(Receiver, self).__init__()\n","        self.fc1 = nn.Linear(message_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, action_size)\n","\n","    def forward(self, message):\n","        hidden = torch.relu(self.fc1(message))\n","        action_logits = self.fc2(hidden)\n","        return action_logits\n","\n","# Initialize models, loss function, and optimizers\n","sender = Sender(STATE_SIZE, HIDDEN_SIZE, MESSAGE_SIZE)\n","receiver = Receiver(MESSAGE_SIZE, HIDDEN_SIZE, STATE_SIZE)  # Receiver now outputs states\n","feedback_sender = Sender(MESSAGE_SIZE, HIDDEN_SIZE, MESSAGE_SIZE)  # Sender to process receiver's message\n","final_receiver = Receiver(MESSAGE_SIZE, HIDDEN_SIZE, ACTION_SIZE)  # Final receiver\n","\n","criterion = nn.CrossEntropyLoss()\n","sender_optimizer = optim.Adam(list(sender.parameters()) + list(feedback_sender.parameters()), lr=LEARNING_RATE)\n","receiver_optimizer = optim.Adam(list(receiver.parameters()) + list(final_receiver.parameters()), lr=LEARNING_RATE)\n","\n","# Training loop\n","for epoch in range(NUM_EPOCHS):\n","    sender_optimizer.zero_grad()\n","    receiver_optimizer.zero_grad()\n","\n","    # Generate a batch of data\n","    state_batch, action_batch = get_batch(BATCH_SIZE)\n","\n","    # Forward pass through the first sender and receiver\n","    messages = sender(state_batch)\n","    reconstructed_states = receiver(messages)\n","\n","    # Forward pass through the feedback sender and final receiver\n","    feedback_messages = feedback_sender(reconstructed_states)\n","    action_logits = final_receiver(feedback_messages)\n","\n","    # Compute loss\n","    loss = criterion(action_logits, action_batch)\n","\n","    # Backward pass and optimization\n","    loss.backward()\n","    sender_optimizer.step()\n","    receiver_optimizer.step()\n","\n","    # Logging\n","    if epoch % 500 == 0:\n","        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n","\n","# Inspect messages and accuracy\n","for i in range(STATE_SIZE):\n","    state = states[i].unsqueeze(0)  # Add batch dimension\n","    message = sender(state)\n","    reconstructed_state = receiver(message)\n","    feedback_message = feedback_sender(reconstructed_state)\n","    action_logits = final_receiver(feedback_message)\n","    predicted_action = action_logits.argmax(dim=1).item()\n","    print(f\"State: {state.numpy()}, Message1: {message.detach().numpy()}, Reconstructed State: {reconstructed_state.detach().numpy()}, Message2: {feedback_message.detach().numpy()}, Predicted Action: {predicted_action}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":519},"id":"DpIFeTcbVhPp","executionInfo":{"status":"error","timestamp":1737303144326,"user_tz":360,"elapsed":355,"user":{"displayName":"Alan Mauricio Camargo Hernandez","userId":"09753390928466343821"}},"outputId":"bb154933-53db-4e74-f616-435466cc83ba"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (32x3 and 1x16)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-a43992f33620>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m# Forward pass through the feedback sender and final receiver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mfeedback_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeedback_sender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstructed_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0maction_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_receiver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeedback_messages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-a43992f33620>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Message bounded between 0 and 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x3 and 1x16)"]}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import random\n","\n","# Hyperparameters\n","NUM_EPOCHS = 5000\n","LEARNING_RATE = 0.01\n","MESSAGE_SIZE = 1  # Single value per message\n","STATE_SIZE = 3\n","ACTION_SIZE = 3\n","HIDDEN_SIZE = 16\n","BATCH_SIZE = 32\n","\n","# Generate synthetic data: states and corresponding correct actions\n","states = torch.eye(STATE_SIZE)\n","correct_actions = torch.arange(ACTION_SIZE)\n","\n","def get_batch(batch_size):\n","    indices = random.choices(range(STATE_SIZE), k=batch_size)\n","    return states[indices], correct_actions[indices]\n","\n","# Define the agent model\n","class Agent(nn.Module):\n","    def __init__(self, input_size, hidden_size, message_size):\n","        super(Agent, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.fc2_message = nn.Linear(hidden_size, message_size)\n","        self.fc2_action = nn.Linear(hidden_size, ACTION_SIZE)\n","\n","    def forward(self, input_data):\n","        hidden = torch.relu(self.fc1(input_data))\n","        message = torch.sigmoid(self.fc2_message(hidden))  # Message bounded between 0 and 1\n","        action_logits = self.fc2_action(hidden)\n","        return message, action_logits\n","\n","# Initialize agents\n","agent1 = Agent(STATE_SIZE + MESSAGE_SIZE, HIDDEN_SIZE, MESSAGE_SIZE)\n","agent2 = Agent(STATE_SIZE + MESSAGE_SIZE, HIDDEN_SIZE, MESSAGE_SIZE)\n","\n","# Loss and optimizers\n","criterion = nn.CrossEntropyLoss()\n","optimizer1 = optim.Adam(agent1.parameters(), lr=LEARNING_RATE)\n","optimizer2 = optim.Adam(agent2.parameters(), lr=LEARNING_RATE)\n","\n","# Training loop\n","for epoch in range(NUM_EPOCHS):\n","    optimizer1.zero_grad()\n","    optimizer2.zero_grad()\n","\n","    # Generate a batch of data\n","    state_batch, action_batch = get_batch(BATCH_SIZE)\n","    initial_message = torch.zeros(BATCH_SIZE, MESSAGE_SIZE)  # Initial message\n","\n","    # Agent 1 sends the first message\n","    input1 = torch.cat((state_batch, initial_message), dim=1)\n","    message1, _ = agent1(input1)\n","\n","    # Agent 2 receives the message, processes it, and sends a response\n","    input2 = torch.cat((state_batch, message1), dim=1)\n","    message2, action_logits2 = agent2(input2)\n","\n","    # Agent 1 receives the response and takes a final action\n","    input1_response = torch.cat((state_batch, message2), dim=1)\n","    _, action_logits1 = agent1(input1_response)\n","\n","    # Compute losses\n","    loss1 = criterion(action_logits1, action_batch)\n","    loss2 = criterion(action_logits2, action_batch)\n","\n","    # Backpropagation\n","    total_loss = loss1 + loss2\n","    total_loss.backward()\n","\n","    optimizer1.step()\n","    optimizer2.step()\n","\n","    # Logging progress\n","    if (epoch + 1) % 500 == 0:\n","        print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Loss: {total_loss.item()}\")\n","\n","# Inspect messages and actions\n","for i in range(STATE_SIZE):\n","    state = states[i].unsqueeze(0)\n","    initial_message = torch.zeros(1, MESSAGE_SIZE)\n","\n","    # Agent 1 sends the first message\n","    input1 = torch.cat((state, initial_message), dim=1)\n","    message1, _ = agent1(input1)\n","\n","    # Agent 2 responds\n","    input2 = torch.cat((state, message1), dim=1)\n","    message2, action_logits2 = agent2(input2)\n","\n","    # Agent 1 final action\n","    input1_response = torch.cat((state, message2), dim=1)\n","    _, action_logits1 = agent1(input1_response)\n","\n","    print(f\"State: {state.numpy()}, Message1: {message1.detach().numpy()}, Message2: {message2.detach().numpy()}, Final Action: {action_logits1.argmax(dim=1).item()}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fe5G67nWWuzZ","executionInfo":{"status":"ok","timestamp":1737311167239,"user_tz":360,"elapsed":12229,"user":{"displayName":"Alan Mauricio Camargo Hernandez","userId":"09753390928466343821"}},"outputId":"d9a54131-737c-4863-acc4-68f430d4c26b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 500/5000, Loss: 0.0012976792640984058\n","Epoch 1000/5000, Loss: 0.00032549319439567626\n","Epoch 1500/5000, Loss: 0.00016904546646401286\n","Epoch 2000/5000, Loss: 9.745090210344642e-05\n","Epoch 2500/5000, Loss: 5.564751336351037e-05\n","Epoch 3000/5000, Loss: 3.43170395353809e-05\n","Epoch 3500/5000, Loss: 2.369268622715026e-05\n","Epoch 4000/5000, Loss: 1.610063191037625e-05\n","Epoch 4500/5000, Loss: 1.1816582627943717e-05\n","Epoch 5000/5000, Loss: 9.141838745563291e-06\n","State: [[1. 0. 0.]], Message1: [[0.9830784]], Message2: [[0.01434786]], Final Action: 0\n","State: [[0. 1. 0.]], Message1: [[0.99918836]], Message2: [[0.00651736]], Final Action: 1\n","State: [[0. 0. 1.]], Message1: [[0.02370292]], Message2: [[0.99716705]], Final Action: 2\n"]}]},{"cell_type":"code","source":["# Redes Neuronales y Entrenamiento de Agentes con Comunicación Bidireccional\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import random\n","\n","# Hyperparámetros\n","NUM_EPOCHS = 100\n","LEARNING_RATE = 0.01\n","MESSAGE_SIZE = 1\n","STATE_SIZE = 3\n","ACTION_SIZE = 3\n","HIDDEN_SIZE = 16\n","BATCH_SIZE = 32\n","\n","# Generar datos sintéticos\n","states = torch.eye(STATE_SIZE)\n","correct_actions = torch.arange(ACTION_SIZE)\n","\n","# Generar lotes de entrenamiento\n","def get_batch(batch_size):\n","    indices = random.choices(range(STATE_SIZE), k=batch_size)\n","    return states[indices], correct_actions[indices]\n","\n","# Modelo de Agente\n","class Agent(nn.Module):\n","    def __init__(self, input_size, hidden_size, message_size):\n","        super(Agent, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.fc2_message = nn.Linear(hidden_size, message_size)\n","        self.fc2_action = nn.Linear(hidden_size, ACTION_SIZE)\n","\n","    def forward(self, input_data):\n","        hidden = torch.relu(self.fc1(input_data))\n","        message = torch.sigmoid(self.fc2_message(hidden))\n","        action_logits = self.fc2_action(hidden)\n","        return message, action_logits\n","\n","# Inicializar agentes\n","agent1 = Agent(STATE_SIZE + MESSAGE_SIZE, HIDDEN_SIZE, MESSAGE_SIZE)\n","agent2 = Agent(STATE_SIZE + MESSAGE_SIZE, HIDDEN_SIZE, MESSAGE_SIZE)\n","\n","# Función de pérdida y optimizadores\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(list(agent1.parameters()) + list(agent2.parameters()), lr=LEARNING_RATE)\n","\n","# Entrenamiento\n","for epoch in range(NUM_EPOCHS):\n","    optimizer.zero_grad()\n","\n","    # Obtener un lote\n","    state_batch, action_batch = get_batch(BATCH_SIZE)\n","\n","    # Mensaje inicial (todo ceros)\n","    message1_to_2 = torch.zeros((BATCH_SIZE, MESSAGE_SIZE))\n","\n","    # Agente 1 envía mensaje al Agente 2\n","    input1 = torch.cat((state_batch, message1_to_2), dim=1)\n","    message2_to_1, _ = agent1(input1)\n","\n","    # Agente 2 envía mensaje de regreso a Agente 1\n","    input2 = torch.cat((state_batch, message2_to_1), dim=1)\n","    message1_final, action_logits2 = agent2(input2)\n","\n","    # Agente 1 toma una decisión final basada en el mensaje recibido\n","    input1_final = torch.cat((state_batch, message1_final), dim=1)\n","    _, action_logits1 = agent1(input1_final)\n","\n","    # Calcular pérdida\n","    loss1 = criterion(action_logits1, action_batch)\n","    loss2 = criterion(action_logits2, action_batch)\n","    loss = loss1 + loss2\n","\n","    # Optimización\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Imprimir evolución cada 500 épocas\n","    if epoch % 5 == 0:\n","        print(f\"Época {epoch}, Pérdida: {loss.item():.4f}\")\n","\n","# Evaluación de la comunicación emergente\n","print(\"\\\\nEvolución de la Comunicación:\")\n","for i in range(STATE_SIZE):\n","    state = states[i].unsqueeze(0)\n","    message1_to_2 = torch.zeros((1, MESSAGE_SIZE))\n","\n","    # Comunicación entre agentes\n","    input1 = torch.cat((state, message1_to_2), dim=1)\n","    message2_to_1, _ = agent1(input1)\n","\n","    input2 = torch.cat((state, message2_to_1), dim=1)\n","    message1_final, _ = agent2(input2)\n","\n","    print(f\"Estado: {state.numpy()}, Mensaje Agente 1 -> 2: {message2_to_1.item():.4f}, \"\n","          f\"Mensaje Agente 2 -> 1: {message1_final.item():.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZbnyjkzlXi9B","executionInfo":{"status":"ok","timestamp":1737310571401,"user_tz":360,"elapsed":753,"user":{"displayName":"Alan Mauricio Camargo Hernandez","userId":"09753390928466343821"}},"outputId":"7e85c337-c3c6-4091-ac96-52ce46d3c9b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Época 0, Pérdida: 2.2684\n","Época 5, Pérdida: 2.0947\n","Época 10, Pérdida: 1.8260\n","Época 15, Pérdida: 1.5284\n","Época 20, Pérdida: 1.3096\n","Época 25, Pérdida: 0.9657\n","Época 30, Pérdida: 0.7049\n","Época 35, Pérdida: 0.4866\n","Época 40, Pérdida: 0.3367\n","Época 45, Pérdida: 0.2009\n","Época 50, Pérdida: 0.1355\n","Época 55, Pérdida: 0.1008\n","Época 60, Pérdida: 0.0692\n","Época 65, Pérdida: 0.0505\n","Época 70, Pérdida: 0.0392\n","Época 75, Pérdida: 0.0316\n","Época 80, Pérdida: 0.0268\n","Época 85, Pérdida: 0.0228\n","Época 90, Pérdida: 0.0200\n","Época 95, Pérdida: 0.0177\n","\\nEvolución de la Comunicación:\n","Estado: [[1. 0. 0.]], Mensaje Agente 1 -> 2: 0.9753, Mensaje Agente 2 -> 1: 0.9493\n","Estado: [[0. 1. 0.]], Mensaje Agente 1 -> 2: 0.9612, Mensaje Agente 2 -> 1: 0.9610\n","Estado: [[0. 0. 1.]], Mensaje Agente 1 -> 2: 0.3432, Mensaje Agente 2 -> 1: 0.9238\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import random\n","\n","# Hyperparameters\n","NUM_EPOCHS = 100\n","LEARNING_RATE = 0.01\n","MESSAGE_SIZE = 1  # Single value per message\n","STATE_SIZE = 5\n","ACTION_SIZE = 5\n","HIDDEN_SIZE = 16\n","BATCH_SIZE = 32\n","\n","# Generate synthetic data: states and corresponding correct actions\n","states = torch.eye(STATE_SIZE)\n","correct_actions = torch.arange(ACTION_SIZE)\n","\n","def get_batch(batch_size):\n","    indices = random.choices(range(STATE_SIZE), k=batch_size)\n","    return states[indices], correct_actions[indices]\n","\n","# Define the agent model\n","class Agent(nn.Module):\n","    def __init__(self, input_size, hidden_size, message_size):\n","        super(Agent, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.fc2_message = nn.Linear(hidden_size, message_size)\n","        self.fc2_action = nn.Linear(hidden_size, ACTION_SIZE)\n","\n","    def forward(self, input_data):\n","        hidden = torch.relu(self.fc1(input_data))\n","        message = torch.sigmoid(self.fc2_message(hidden))  # Message bounded between 0 and 1\n","        action_logits = self.fc2_action(hidden)\n","        return message, action_logits\n","\n","# Initialize agents\n","agent1 = Agent(STATE_SIZE + MESSAGE_SIZE, HIDDEN_SIZE, MESSAGE_SIZE)\n","agent2 = Agent(STATE_SIZE + MESSAGE_SIZE, HIDDEN_SIZE, MESSAGE_SIZE)\n","\n","# Loss and optimizers\n","criterion = nn.CrossEntropyLoss()\n","optimizer1 = optim.Adam(agent1.parameters(), lr=LEARNING_RATE)\n","optimizer2 = optim.Adam(agent2.parameters(), lr=LEARNING_RATE)\n","\n","# Training loop\n","for epoch in range(NUM_EPOCHS):\n","    optimizer1.zero_grad()\n","    optimizer2.zero_grad()\n","\n","    # Generate a batch of data\n","    state_batch, action_batch = get_batch(BATCH_SIZE)\n","    initial_message = torch.zeros(BATCH_SIZE, MESSAGE_SIZE)  # Initial message\n","\n","    # Agent 1 sends the first message\n","    input1 = torch.cat((state_batch, initial_message), dim=1)\n","    message1, _ = agent1(input1)\n","\n","    # Agent 2 receives the message, processes it, and sends a response\n","    input2 = torch.cat((state_batch, message1), dim=1)\n","    message2, action_logits2 = agent2(input2)\n","\n","    # Agent 1 receives the response and takes a final action\n","    input1_response = torch.cat((state_batch, message2), dim=1)\n","    _, action_logits1 = agent1(input1_response)\n","\n","    # Compute losses\n","    loss1 = criterion(action_logits1, action_batch)\n","    loss2 = criterion(action_logits2, action_batch)\n","\n","    # Backpropagation\n","    total_loss = loss1 + loss2\n","    total_loss.backward()\n","\n","    optimizer1.step()\n","    optimizer2.step()\n","\n","    # Log results every 500 epochs\n","    if (epoch + 1) % 5 == 0:\n","        print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}\")\n","        print(f\"Loss1: {loss1.item():.4f}, Loss2: {loss2.item():.4f}\")\n","\n","        # Show some messages and actions\n","        for i in range(5):  # Display for first 3 states\n","            state = states[i].unsqueeze(0)\n","            initial_message = torch.zeros(1, MESSAGE_SIZE)\n","\n","            input1 = torch.cat((state, initial_message), dim=1)\n","            message1, _ = agent1(input1)\n","\n","            input2 = torch.cat((state, message1), dim=1)\n","            message2, action_logits2 = agent2(input2)\n","\n","            input1_response = torch.cat((state, message2), dim=1)\n","            _, action_logits1 = agent1(input1_response)\n","\n","            print(f\"  State: {state.numpy().flatten()}\")\n","            print(f\"  Message1: {message1.detach().numpy().flatten()}\")\n","            print(f\"  Message2: {message2.detach().numpy().flatten()}\")\n","            print(f\"  Action2: {action_logits2.argmax(dim=1).item()}, Action1: {action_logits1.argmax(dim=1).item()}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mPR0lUFV0Iu0","executionInfo":{"status":"ok","timestamp":1737311566112,"user_tz":360,"elapsed":1275,"user":{"displayName":"Alan Mauricio Camargo Hernandez","userId":"09753390928466343821"}},"outputId":"ce9e0071-bc38-4e35-d19d-05dcb285a941"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 5/100\n","Loss1: 1.6004, Loss2: 1.5896\n","  State: [1. 0. 0. 0. 0.]\n","  Message1: [0.54031336]\n","  Message2: [0.48619798]\n","  Action2: 1, Action1: 1\n","  State: [0. 1. 0. 0. 0.]\n","  Message1: [0.53372437]\n","  Message2: [0.5287939]\n","  Action2: 1, Action1: 3\n","  State: [0. 0. 1. 0. 0.]\n","  Message1: [0.5631246]\n","  Message2: [0.50661886]\n","  Action2: 1, Action1: 3\n","  State: [0. 0. 0. 1. 0.]\n","  Message1: [0.5530909]\n","  Message2: [0.50247926]\n","  Action2: 1, Action1: 3\n","  State: [0. 0. 0. 0. 1.]\n","  Message1: [0.52037525]\n","  Message2: [0.5054932]\n","  Action2: 1, Action1: 3\n","Epoch 10/100\n","Loss1: 1.4597, Loss2: 1.4484\n","  State: [1. 0. 0. 0. 0.]\n","  Message1: [0.54158807]\n","  Message2: [0.50353175]\n","  Action2: 0, Action1: 1\n","  State: [0. 1. 0. 0. 0.]\n","  Message1: [0.5418952]\n","  Message2: [0.5275436]\n","  Action2: 1, Action1: 1\n","  State: [0. 0. 1. 0. 0.]\n","  Message1: [0.5894121]\n","  Message2: [0.51042616]\n","  Action2: 1, Action1: 2\n","  State: [0. 0. 0. 1. 0.]\n","  Message1: [0.5684534]\n","  Message2: [0.52803236]\n","  Action2: 1, Action1: 3\n","  State: [0. 0. 0. 0. 1.]\n","  Message1: [0.51196486]\n","  Message2: [0.52627873]\n","  Action2: 1, Action1: 3\n","Epoch 15/100\n","Loss1: 1.3641, Loss2: 1.3319\n","  State: [1. 0. 0. 0. 0.]\n","  Message1: [0.5421105]\n","  Message2: [0.5210325]\n","  Action2: 0, Action1: 1\n","  State: [0. 1. 0. 0. 0.]\n","  Message1: [0.55035096]\n","  Message2: [0.5212157]\n","  Action2: 1, Action1: 1\n","  State: [0. 0. 1. 0. 0.]\n","  Message1: [0.61468655]\n","  Message2: [0.51562256]\n","  Action2: 2, Action1: 2\n","  State: [0. 0. 0. 1. 0.]\n","  Message1: [0.5925977]\n","  Message2: [0.5590723]\n","  Action2: 3, Action1: 3\n","  State: [0. 0. 0. 0. 1.]\n","  Message1: [0.5016971]\n","  Message2: [0.54146886]\n","  Action2: 4, Action1: 4\n","Epoch 20/100\n","Loss1: 1.2101, Loss2: 1.1886\n","  State: [1. 0. 0. 0. 0.]\n","  Message1: [0.5487708]\n","  Message2: [0.5481084]\n","  Action2: 0, Action1: 0\n","  State: [0. 1. 0. 0. 0.]\n","  Message1: [0.56886065]\n","  Message2: [0.50534165]\n","  Action2: 1, Action1: 1\n","  State: [0. 0. 1. 0. 0.]\n","  Message1: [0.64643615]\n","  Message2: [0.52425194]\n","  Action2: 2, Action1: 2\n","  State: [0. 0. 0. 1. 0.]\n","  Message1: [0.6276106]\n","  Message2: [0.59686005]\n","  Action2: 3, Action1: 3\n","  State: [0. 0. 0. 0. 1.]\n","  Message1: [0.5032896]\n","  Message2: [0.5548412]\n","  Action2: 4, Action1: 4\n","Epoch 25/100\n","Loss1: 1.0763, Loss2: 0.9850\n","  State: [1. 0. 0. 0. 0.]\n","  Message1: [0.55652803]\n","  Message2: [0.575288]\n","  Action2: 0, Action1: 0\n","  State: [0. 1. 0. 0. 0.]\n","  Message1: [0.5962916]\n","  Message2: [0.4823635]\n","  Action2: 1, Action1: 1\n","  State: [0. 0. 1. 0. 0.]\n","  Message1: [0.6953886]\n","  Message2: [0.5362012]\n","  Action2: 2, Action1: 2\n","  State: [0. 0. 0. 1. 0.]\n","  Message1: [0.67717695]\n","  Message2: [0.63056725]\n","  Action2: 3, Action1: 3\n","  State: [0. 0. 0. 0. 1.]\n","  Message1: [0.5160624]\n","  Message2: [0.552246]\n","  Action2: 4, Action1: 4\n","Epoch 30/100\n","Loss1: 0.8787, Loss2: 0.8261\n","  State: [1. 0. 0. 0. 0.]\n","  Message1: [0.5562482]\n","  Message2: [0.6139085]\n","  Action2: 0, Action1: 0\n","  State: [0. 1. 0. 0. 0.]\n","  Message1: [0.62388855]\n","  Message2: [0.47324434]\n","  Action2: 1, Action1: 1\n","  State: [0. 0. 1. 0. 0.]\n","  Message1: [0.7164301]\n","  Message2: [0.562279]\n","  Action2: 2, Action1: 2\n","  State: [0. 0. 0. 1. 0.]\n","  Message1: [0.7312902]\n","  Message2: [0.67789406]\n","  Action2: 3, Action1: 3\n","  State: [0. 0. 0. 0. 1.]\n","  Message1: [0.5246807]\n","  Message2: [0.56082803]\n","  Action2: 4, Action1: 4\n","Epoch 35/100\n","Loss1: 0.6833, Loss2: 0.7141\n","  State: [1. 0. 0. 0. 0.]\n","  Message1: [0.55104727]\n","  Message2: [0.6668845]\n","  Action2: 0, Action1: 0\n","  State: [0. 1. 0. 0. 0.]\n","  Message1: [0.65271056]\n","  Message2: [0.4786532]\n","  Action2: 1, Action1: 1\n","  State: [0. 0. 1. 0. 0.]\n","  Message1: [0.7343453]\n","  Message2: [0.6119808]\n","  Action2: 2, Action1: 2\n","  State: [0. 0. 0. 1. 0.]\n","  Message1: [0.787109]\n","  Message2: [0.7404588]\n","  Action2: 3, Action1: 3\n","  State: [0. 0. 0. 0. 1.]\n","  Message1: [0.54219323]\n","  Message2: [0.5777679]\n","  Action2: 4, Action1: 4\n","Epoch 40/100\n","Loss1: 0.6258, Loss2: 0.5191\n","  State: [1. 0. 0. 0. 0.]\n","  Message1: [0.55432]\n","  Message2: [0.7123078]\n","  Action2: 0, Action1: 0\n","  State: [0. 1. 0. 0. 0.]\n","  Message1: [0.6881988]\n","  Message2: [0.47109148]\n","  Action2: 1, Action1: 1\n","  State: [0. 0. 1. 0. 0.]\n","  Message1: [0.7697222]\n","  Message2: [0.6657064]\n","  Action2: 2, Action1: 2\n","  State: [0. 0. 0. 1. 0.]\n","  Message1: [0.8447349]\n","  Message2: [0.79335016]\n","  Action2: 3, Action1: 3\n","  State: [0. 0. 0. 0. 1.]\n","  Message1: [0.58803374]\n","  Message2: [0.59669]\n","  Action2: 4, Action1: 4\n","Epoch 45/100\n","Loss1: 0.3750, Loss2: 0.3691\n","  State: [1. 0. 0. 0. 0.]\n","  Message1: [0.54760617]\n","  Message2: [0.75479716]\n","  Action2: 0, Action1: 0\n","  State: [0. 1. 0. 0. 0.]\n","  Message1: [0.72046506]\n","  Message2: [0.4834226]\n","  Action2: 1, Action1: 1\n","  State: [0. 0. 1. 0. 0.]\n","  Message1: [0.7943383]\n","  Message2: [0.72973746]\n","  Action2: 2, Action1: 2\n","  State: [0. 0. 0. 1. 0.]\n","  Message1: [0.8870475]\n","  Message2: [0.84460396]\n","  Action2: 3, Action1: 3\n","  State: [0. 0. 0. 0. 1.]\n","  Message1: [0.61974525]\n","  Message2: [0.619735]\n","  Action2: 4, Action1: 4\n","Epoch 50/100\n","Loss1: 0.2669, Loss2: 0.2590\n","  State: [1. 0. 0. 0. 0.]\n","  Message1: [0.55380255]\n","  Message2: [0.80850476]\n","  Action2: 0, Action1: 0\n","  State: [0. 1. 0. 0. 0.]\n","  Message1: [0.76194817]\n","  Message2: [0.5312865]\n","  Action2: 1, Action1: 1\n","  State: [0. 0. 1. 0. 0.]\n","  Message1: [0.82347184]\n","  Message2: [0.80606276]\n","  Action2: 2, Action1: 2\n","  State: [0. 0. 0. 1. 0.]\n","  Message1: [0.91511214]\n","  Message2: [0.8970999]\n","  Action2: 3, Action1: 3\n","  State: [0. 0. 0. 0. 1.]\n","  Message1: [0.6418043]\n","  Message2: [0.65283424]\n","  Action2: 4, Action1: 4\n","Epoch 55/100\n","Loss1: 0.1625, Loss2: 0.1598\n","  State: [1. 0. 0. 0. 0.]\n","  Message1: [0.57085675]\n","  Message2: [0.85359436]\n","  Action2: 0, Action1: 0\n","  State: [0. 1. 0. 0. 0.]\n","  Message1: [0.80068696]\n","  Message2: [0.5582592]\n","  Action2: 1, Action1: 1\n","  State: [0. 0. 1. 0. 0.]\n","  Message1: [0.85905075]\n","  Message2: [0.8619127]\n","  Action2: 2, Action1: 2\n","  State: [0. 0. 0. 1. 0.]\n","  Message1: [0.9340389]\n","  Message2: [0.93080413]\n","  Action2: 3, Action1: 3\n","  State: [0. 0. 0. 0. 1.]\n","  Message1: [0.6551868]\n","  Message2: [0.66752887]\n","  Action2: 4, Action1: 4\n","Epoch 60/100\n","Loss1: 0.1247, Loss2: 0.1145\n","  State: [1. 0. 0. 0. 0.]\n","  Message1: [0.57890147]\n","  Message2: [0.89126384]\n","  Action2: 0, Action1: 0\n","  State: [0. 1. 0. 0. 0.]\n","  Message1: [0.83199155]\n","  Message2: [0.6059365]\n","  Action2: 1, Action1: 1\n","  State: [0. 0. 1. 0. 0.]\n","  Message1: [0.8853901]\n","  Message2: [0.90620613]\n","  Action2: 2, Action1: 2\n","  State: [0. 0. 0. 1. 0.]\n","  Message1: [0.94564396]\n","  Message2: [0.9548299]\n","  Action2: 3, Action1: 3\n","  State: [0. 0. 0. 0. 1.]\n","  Message1: [0.6523429]\n","  Message2: [0.68327177]\n","  Action2: 4, Action1: 4\n","Epoch 65/100\n","Loss1: 0.0789, Loss2: 0.0832\n","  State: [1. 0. 0. 0. 0.]\n","  Message1: [0.5768267]\n","  Message2: [0.9203111]\n","  Action2: 0, Action1: 0\n","  State: [0. 1. 0. 0. 0.]\n","  Message1: [0.85623896]\n","  Message2: [0.6511906]\n","  Action2: 1, Action1: 1\n","  State: [0. 0. 1. 0. 0.]\n","  Message1: [0.9028228]\n","  Message2: [0.93457896]\n","  Action2: 2, Action1: 2\n","  State: [0. 0. 0. 1. 0.]\n","  Message1: [0.95372075]\n","  Message2: [0.9700262]\n","  Action2: 3, Action1: 3\n","  State: [0. 0. 0. 0. 1.]\n","  Message1: [0.6454018]\n","  Message2: [0.7118885]\n","  Action2: 4, Action1: 4\n","Epoch 70/100\n","Loss1: 0.0578, Loss2: 0.0586\n","  State: [1. 0. 0. 0. 0.]\n","  Message1: [0.58041704]\n","  Message2: [0.9404429]\n","  Action2: 0, Action1: 0\n","  State: [0. 1. 0. 0. 0.]\n","  Message1: [0.87675905]\n","  Message2: [0.6849318]\n","  Action2: 1, Action1: 1\n","  State: [0. 0. 1. 0. 0.]\n","  Message1: [0.9179472]\n","  Message2: [0.9526212]\n","  Action2: 2, Action1: 2\n","  State: [0. 0. 0. 1. 0.]\n","  Message1: [0.96121866]\n","  Message2: [0.9791586]\n","  Action2: 3, Action1: 3\n","  State: [0. 0. 0. 0. 1.]\n","  Message1: [0.6568603]\n","  Message2: [0.74085057]\n","  Action2: 4, Action1: 4\n","Epoch 75/100\n","Loss1: 0.0406, Loss2: 0.0414\n","  State: [1. 0. 0. 0. 0.]\n","  Message1: [0.593409]\n","  Message2: [0.9525033]\n","  Action2: 0, Action1: 0\n","  State: [0. 1. 0. 0. 0.]\n","  Message1: [0.8919726]\n","  Message2: [0.6892888]\n","  Action2: 1, Action1: 1\n","  State: [0. 0. 1. 0. 0.]\n","  Message1: [0.92947316]\n","  Message2: [0.96221656]\n","  Action2: 2, Action1: 2\n","  State: [0. 0. 0. 1. 0.]\n","  Message1: [0.96663684]\n","  Message2: [0.98366183]\n","  Action2: 3, Action1: 3\n","  State: [0. 0. 0. 0. 1.]\n","  Message1: [0.67054063]\n","  Message2: [0.7556141]\n","  Action2: 4, Action1: 4\n","Epoch 80/100\n","Loss1: 0.0342, Loss2: 0.0348\n","  State: [1. 0. 0. 0. 0.]\n","  Message1: [0.5946653]\n","  Message2: [0.958807]\n","  Action2: 0, Action1: 0\n","  State: [0. 1. 0. 0. 0.]\n","  Message1: [0.9024412]\n","  Message2: [0.6868682]\n","  Action2: 1, Action1: 1\n","  State: [0. 0. 1. 0. 0.]\n","  Message1: [0.9353661]\n","  Message2: [0.9677528]\n","  Action2: 2, Action1: 2\n","  State: [0. 0. 0. 1. 0.]\n","  Message1: [0.96990585]\n","  Message2: [0.9861324]\n","  Action2: 3, Action1: 3\n","  State: [0. 0. 0. 0. 1.]\n","  Message1: [0.67101955]\n","  Message2: [0.75554353]\n","  Action2: 4, Action1: 4\n","Epoch 85/100\n","Loss1: 0.0268, Loss2: 0.0274\n","  State: [1. 0. 0. 0. 0.]\n","  Message1: [0.59741485]\n","  Message2: [0.96351916]\n","  Action2: 0, Action1: 0\n","  State: [0. 1. 0. 0. 0.]\n","  Message1: [0.91076505]\n","  Message2: [0.6966426]\n","  Action2: 1, Action1: 1\n","  State: [0. 0. 1. 0. 0.]\n","  Message1: [0.9396423]\n","  Message2: [0.9725284]\n","  Action2: 2, Action1: 2\n","  State: [0. 0. 0. 1. 0.]\n","  Message1: [0.972305]\n","  Message2: [0.98817164]\n","  Action2: 3, Action1: 3\n","  State: [0. 0. 0. 0. 1.]\n","  Message1: [0.6689794]\n","  Message2: [0.76199764]\n","  Action2: 4, Action1: 4\n","Epoch 90/100\n","Loss1: 0.0221, Loss2: 0.0219\n","  State: [1. 0. 0. 0. 0.]\n","  Message1: [0.5983872]\n","  Message2: [0.9672702]\n","  Action2: 0, Action1: 0\n","  State: [0. 1. 0. 0. 0.]\n","  Message1: [0.91819155]\n","  Message2: [0.71478105]\n","  Action2: 1, Action1: 1\n","  State: [0. 0. 1. 0. 0.]\n","  Message1: [0.94295853]\n","  Message2: [0.9765887]\n","  Action2: 2, Action1: 2\n","  State: [0. 0. 0. 1. 0.]\n","  Message1: [0.97430384]\n","  Message2: [0.98987776]\n","  Action2: 3, Action1: 3\n","  State: [0. 0. 0. 0. 1.]\n","  Message1: [0.67057544]\n","  Message2: [0.776011]\n","  Action2: 4, Action1: 4\n","Epoch 95/100\n","Loss1: 0.0176, Loss2: 0.0192\n","  State: [1. 0. 0. 0. 0.]\n","  Message1: [0.5907963]\n","  Message2: [0.9695292]\n","  Action2: 0, Action1: 0\n","  State: [0. 1. 0. 0. 0.]\n","  Message1: [0.9241288]\n","  Message2: [0.72815907]\n","  Action2: 1, Action1: 1\n","  State: [0. 0. 1. 0. 0.]\n","  Message1: [0.9448338]\n","  Message2: [0.97947764]\n","  Action2: 2, Action1: 2\n","  State: [0. 0. 0. 1. 0.]\n","  Message1: [0.9757293]\n","  Message2: [0.9909977]\n","  Action2: 3, Action1: 3\n","  State: [0. 0. 0. 0. 1.]\n","  Message1: [0.6717041]\n","  Message2: [0.7833486]\n","  Action2: 4, Action1: 4\n","Epoch 100/100\n","Loss1: 0.0166, Loss2: 0.0182\n","  State: [1. 0. 0. 0. 0.]\n","  Message1: [0.5910276]\n","  Message2: [0.97127616]\n","  Action2: 0, Action1: 0\n","  State: [0. 1. 0. 0. 0.]\n","  Message1: [0.92853683]\n","  Message2: [0.73300266]\n","  Action2: 1, Action1: 1\n","  State: [0. 0. 1. 0. 0.]\n","  Message1: [0.94716376]\n","  Message2: [0.9814156]\n","  Action2: 2, Action1: 2\n","  State: [0. 0. 0. 1. 0.]\n","  Message1: [0.9769811]\n","  Message2: [0.9916842]\n","  Action2: 3, Action1: 3\n","  State: [0. 0. 0. 0. 1.]\n","  Message1: [0.6752549]\n","  Message2: [0.78601384]\n","  Action2: 4, Action1: 4\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import random\n","\n","# Hyperparameters\n","STATE_SIZE = 5         # Size of the 1D environment\n","ACTION_SIZE = 3        # Left, Stay, Right\n","HIDDEN_SIZE = 16\n","LEARNING_RATE = 0.01\n","NUM_EPOCHS = 5000\n","BATCH_SIZE = 32\n","\n","# Environment: Simple 1D world\n","class SimpleWorld:\n","    def __init__(self, size, goal_position):\n","        self.size = size\n","        self.goal_position = goal_position\n","\n","    def step(self, state, action):\n","        \"\"\"\n","        Simulates one step in the environment.\n","        Args:\n","            state (torch.Tensor): One-hot encoded current state.\n","            action (int): Action index (0=Left, 1=Stay, 2=Right).\n","        Returns:\n","            next_state (torch.Tensor): One-hot encoded next state.\n","            reward (float): Reward for the transition.\n","        \"\"\"\n","        position = torch.argmax(state).item()\n","        if action == 0:  # Move left\n","            position = max(0, position - 1)\n","        elif action == 2:  # Move right\n","            position = min(self.size - 1, position + 1)\n","        next_state = torch.zeros(self.size)\n","        next_state[position] = 1\n","        reward = 1.0 if position == self.goal_position else -0.1\n","        return next_state, reward\n","\n","# Model of the world\n","class WorldModel(nn.Module):\n","    def __init__(self, state_size, action_size, hidden_size):\n","        super(WorldModel, self).__init__()\n","        self.fc1 = nn.Linear(state_size + action_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, state_size)\n","\n","    def forward(self, state, action):\n","        x = torch.cat((state, action), dim=1)\n","        hidden = torch.relu(self.fc1(x))\n","        next_state_pred = torch.softmax(self.fc2(hidden), dim=1)\n","        return next_state_pred\n","\n","# Training data generation\n","def generate_data(env, num_samples=1000):\n","    states = []\n","    actions = []\n","    next_states = []\n","    for _ in range(num_samples):\n","        state = torch.eye(env.size)[random.randint(0, env.size - 1)]\n","        action = torch.eye(ACTION_SIZE)[random.randint(0, ACTION_SIZE - 1)]\n","        next_state, _ = env.step(state, torch.argmax(action).item())\n","        states.append(state)\n","        actions.append(action)\n","        next_states.append(next_state)\n","    return torch.stack(states), torch.stack(actions), torch.stack(next_states)\n","\n","# Training the world model\n","def train_world_model(world_model, optimizer, criterion, states, actions, next_states, epochs):\n","    for epoch in range(epochs):\n","        optimizer.zero_grad()\n","        predictions = world_model(states, actions)\n","        loss = criterion(predictions, next_states)\n","        loss.backward()\n","        optimizer.step()\n","        if (epoch + 1) % 200 == 0:\n","            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}\")\n","\n","# Agent planning with the world model\n","def plan_with_model(world_model, env, state, max_steps=10):\n","    total_reward = 0\n","    print(\"Planning starts...\")\n","    for step in range(max_steps):\n","        # Try all actions and predict outcomes\n","        action_values = []\n","        for action_idx in range(ACTION_SIZE):\n","            action = torch.eye(ACTION_SIZE)[action_idx].unsqueeze(0)\n","            next_state_pred = world_model(state.unsqueeze(0), action).squeeze(0)\n","            reward = -0.1\n","            if torch.argmax(next_state_pred) == env.goal_position:\n","                reward = 1.0\n","            action_values.append(reward)\n","        # Choose the best action\n","        best_action = int(np.argmax(action_values))\n","        print(f\"Step {step + 1}: Action={best_action}, Predicted reward={action_values[best_action]:.2f}\")\n","        # Simulate action in the real environment\n","        state, reward = env.step(state, best_action)\n","        total_reward += reward\n","        print(f\"Actual state: {state.numpy()}, Reward: {reward:.2f}\")\n","        if reward == 1.0:  # Goal reached\n","            break\n","    print(f\"Total Reward: {total_reward:.2f}\")\n","\n","# Main function\n","if __name__ == \"__main__\":\n","    # Initialize environment and world model\n","    env = SimpleWorld(size=STATE_SIZE, goal_position=STATE_SIZE - 1)\n","    world_model = WorldModel(state_size=STATE_SIZE, action_size=ACTION_SIZE, hidden_size=HIDDEN_SIZE)\n","    optimizer = optim.Adam(world_model.parameters(), lr=LEARNING_RATE)\n","    criterion = nn.MSELoss()\n","\n","    # Generate training data\n","    states, actions, next_states = generate_data(env)\n","\n","    # Train the model of the world\n","    train_world_model(world_model, optimizer, criterion, states, actions, next_states, NUM_EPOCHS)\n","\n","    # Use the trained model to plan\n","    initial_state = torch.eye(STATE_SIZE)[0]  # Start at position 0\n","    plan_with_model(world_model, env, initial_state)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UFxclSKRml6b","executionInfo":{"status":"ok","timestamp":1739314953985,"user_tz":360,"elapsed":8893,"user":{"displayName":"Alan Mauricio Camargo Hernandez","userId":"09753390928466343821"}},"outputId":"c3f21394-422b-441f-e1d5-243b16794d81"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 200/5000, Loss: 0.0002\n","Epoch 400/5000, Loss: 0.0001\n","Epoch 600/5000, Loss: 0.0000\n","Epoch 800/5000, Loss: 0.0000\n","Epoch 1000/5000, Loss: 0.0000\n","Epoch 1200/5000, Loss: 0.0000\n","Epoch 1400/5000, Loss: 0.0000\n","Epoch 1600/5000, Loss: 0.0000\n","Epoch 1800/5000, Loss: 0.0000\n","Epoch 2000/5000, Loss: 0.0000\n","Epoch 2200/5000, Loss: 0.0000\n","Epoch 2400/5000, Loss: 0.0000\n","Epoch 2600/5000, Loss: 0.0000\n","Epoch 2800/5000, Loss: 0.0000\n","Epoch 3000/5000, Loss: 0.0000\n","Epoch 3200/5000, Loss: 0.0000\n","Epoch 3400/5000, Loss: 0.0000\n","Epoch 3600/5000, Loss: 0.0000\n","Epoch 3800/5000, Loss: 0.0000\n","Epoch 4000/5000, Loss: 0.0000\n","Epoch 4200/5000, Loss: 0.0000\n","Epoch 4400/5000, Loss: 0.0000\n","Epoch 4600/5000, Loss: 0.0000\n","Epoch 4800/5000, Loss: 0.0000\n","Epoch 5000/5000, Loss: 0.0000\n","Planning starts...\n","Step 1: Action=0, Predicted reward=-0.10\n","Actual state: [1. 0. 0. 0. 0.], Reward: -0.10\n","Step 2: Action=0, Predicted reward=-0.10\n","Actual state: [1. 0. 0. 0. 0.], Reward: -0.10\n","Step 3: Action=0, Predicted reward=-0.10\n","Actual state: [1. 0. 0. 0. 0.], Reward: -0.10\n","Step 4: Action=0, Predicted reward=-0.10\n","Actual state: [1. 0. 0. 0. 0.], Reward: -0.10\n","Step 5: Action=0, Predicted reward=-0.10\n","Actual state: [1. 0. 0. 0. 0.], Reward: -0.10\n","Step 6: Action=0, Predicted reward=-0.10\n","Actual state: [1. 0. 0. 0. 0.], Reward: -0.10\n","Step 7: Action=0, Predicted reward=-0.10\n","Actual state: [1. 0. 0. 0. 0.], Reward: -0.10\n","Step 8: Action=0, Predicted reward=-0.10\n","Actual state: [1. 0. 0. 0. 0.], Reward: -0.10\n","Step 9: Action=0, Predicted reward=-0.10\n","Actual state: [1. 0. 0. 0. 0.], Reward: -0.10\n","Step 10: Action=0, Predicted reward=-0.10\n","Actual state: [1. 0. 0. 0. 0.], Reward: -0.10\n","Total Reward: -1.00\n"]}]},{"cell_type":"markdown","source":["# imagenes"],"metadata":{"id":"sFIuYJVuYwWa"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import datasets, transforms\n","import random\n","\n","# Hyperparameters\n","NUM_EPOCHS = 10\n","LEARNING_RATE = 0.01\n","MESSAGE_SIZE = 1\n","HIDDEN_SIZE = 16\n","BATCH_SIZE = 32\n","ACTION_SIZE = 5  # 5 images from MNIST\n","\n","# Define image transformation (resize to 64x64 and normalize)\n","transform = transforms.Compose([\n","    transforms.Resize((64, 64)),  # Redimensionar a 64x64\n","    transforms.ToTensor(),  # Convertir a tensor\n","    transforms.Normalize((0.5,), (0.5,))  # Normalizar entre -1 y 1\n","])\n","\n","# Cargar el conjunto de datos MNIST\n","mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","\n","# Seleccionamos 5 imágenes aleatorias\n","indices = random.sample(range(len(mnist_dataset)), 5)\n","images, labels = zip(*[mnist_dataset[i] for i in [1,2,3,6,5]])\n","print(type(labels[0]))\n","# labels = [1,2,3,4,5]\n","# Visualizar las imágenes seleccionadas (opcional)\n","import matplotlib.pyplot as plt\n","for i, img in enumerate(images):\n","    plt.subplot(1, 5, i + 1)\n","    plt.imshow(img.permute(1, 2, 0).numpy().squeeze(), cmap='gray')\n","    plt.title(f\"Label: {labels[i]}\")\n","    plt.axis('off')\n","plt.show()\n","\n","# Define the Sender (CNN that takes an image and generates a message)\n","class Sender(nn.Module):\n","    def __init__(self, message_size):\n","        super(Sender, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n","        self.fc1 = nn.Linear(32 * 64 * 64, 128)\n","        self.fc2 = nn.Linear(128, message_size)\n","\n","    def forward(self, image):\n","        x = torch.relu(self.conv1(image))\n","        x = torch.relu(self.conv2(x))\n","        x = x.view(x.size(0), -1)  # Flatten the tensor\n","        x = torch.relu(self.fc1(x))\n","        message = torch.sigmoid(self.fc2(x))  # Message bounded between 0 and 1\n","        return message\n","\n","# Define the Receiver (MLP that takes a message and predicts an image)\n","class Receiver(nn.Module):\n","    def __init__(self, message_size, action_size):\n","        super(Receiver, self).__init__()\n","        self.fc1 = nn.Linear(message_size, 128)\n","        self.fc2 = nn.Linear(128, action_size)\n","\n","    def forward(self, message):\n","        x = torch.relu(self.fc1(message))\n","        action_logits = self.fc2(x)\n","        return action_logits\n","\n","# Initialize models, loss function, and optimizers\n","sender = Sender(MESSAGE_SIZE)\n","receiver = Receiver(MESSAGE_SIZE, ACTION_SIZE)\n","\n","criterion = nn.CrossEntropyLoss()\n","sender_optimizer = optim.Adam(sender.parameters(), lr=LEARNING_RATE)\n","receiver_optimizer = optim.Adam(receiver.parameters(), lr=LEARNING_RATE)\n","\n","# Training loop\n","for epoch in range(NUM_EPOCHS):\n","    sender_optimizer.zero_grad()\n","    receiver_optimizer.zero_grad()\n","\n","    # Randomly select a batch of images\n","    selected_indices = random.sample(range(5), 1)\n","    selected_image = images[selected_indices[0]].unsqueeze(0)  # Add batch dimension\n","    selected_label = labels[selected_indices[0]]\n","\n","    # Forward pass through Sender\n","    messages = sender(selected_image)\n","\n","    # Forward pass through Receiver\n","    action_logits = receiver(messages)\n","\n","    # Compute loss\n","    loss = criterion(action_logits, torch.tensor([selected_label]))\n","\n","    # Backward pass and optimization\n","    loss.backward()\n","    sender_optimizer.step()\n","    receiver_optimizer.step()\n","\n","    # Print progress every 5 epochs\n","    if (epoch + 1) % 5 == 0:\n","        print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Loss: {loss.item():.4f}\")\n","\n","# Test the Receiver's performance\n","correct = 0\n","for i in range(5):\n","    with torch.no_grad():\n","        selected_image = images[i].unsqueeze(0)  # Add batch dimension\n","        message = sender(selected_image)\n","        action_logits = receiver(message)\n","        predicted_label = torch.argmax(action_logits, dim=1).item()\n","        print(f\"Image {i}: Predicted Label {predicted_label}, True Label {labels[i]}\")\n","        if predicted_label == labels[i]:\n","            correct += 1\n","\n","accuracy = correct / 5\n","print(f\"\\nReceiver Accuracy: {accuracy * 100:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":325},"id":"QPyK0cTLZYq6","outputId":"444e2124-e291-4aac-82f7-2e9e69ecaca7","executionInfo":{"status":"ok","timestamp":1740015606428,"user_tz":360,"elapsed":4194,"user":{"displayName":"Alan Mauricio Camargo Hernandez","userId":"09753390928466343821"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'int'>\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 5 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 5/10, Loss: 0.4531\n","Epoch 10/10, Loss: 0.1149\n","Image 0: Predicted Label 1, True Label 0\n","Image 1: Predicted Label 1, True Label 4\n","Image 2: Predicted Label 1, True Label 1\n","Image 3: Predicted Label 1, True Label 1\n","Image 4: Predicted Label 1, True Label 2\n","\n","Receiver Accuracy: 40.00%\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import datasets, transforms\n","import random\n","\n","# Hyperparameters\n","NUM_EPOCHS = 10\n","LEARNING_RATE = 0.01\n","MESSAGE_SIZE = 1\n","HIDDEN_SIZE = 16\n","BATCH_SIZE = 32\n","ACTION_SIZE = 5  # 5 images from MNIST\n","\n","# Define image transformation (resize to 64x64 and normalize)\n","transform = transforms.Compose([\n","    transforms.Resize((64, 64)),  # Redimensionar a 64x64\n","    transforms.ToTensor(),  # Convertir a tensor\n","    transforms.Normalize((0.5,), (0.5,))  # Normalizar entre -1 y 1\n","])\n","\n","# Cargar el conjunto de datos MNIST\n","mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","\n","# Seleccionamos 5 imágenes aleatorias\n","indices = random.sample(range(len(mnist_dataset)), 5)\n","images, labels = zip(*[mnist_dataset[i] for i in [1,2,3,6,5]])\n","# print(type(labels[0]))\n","labels = (1,2,3,4,5)\n","# Visualizar las imágenes seleccionadas (opcional)\n","import matplotlib.pyplot as plt\n","for i, img in enumerate(images):\n","    plt.subplot(1, 5, i + 1)\n","    plt.imshow(img.permute(1, 2, 0).numpy().squeeze(), cmap='gray')\n","    plt.title(f\"Label: {labels[i]}\")\n","    plt.axis('off')\n","plt.show()\n","\n","# Define the Sender (CNN that takes an image and generates a message)\n","class Sender(nn.Module):\n","    def __init__(self, message_size):\n","        super(Sender, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n","        self.fc1 = nn.Linear(32 * 64 * 64, 128)\n","        self.fc2 = nn.Linear(128, message_size)\n","\n","    def forward(self, image):\n","        x = torch.relu(self.conv1(image))\n","        x = torch.relu(self.conv2(x))\n","        x = x.view(x.size(0), -1)  # Flatten the tensor\n","        x = torch.relu(self.fc1(x))\n","        message = torch.sigmoid(self.fc2(x))  # Message bounded between 0 and 1\n","        return message\n","\n","# Define the Receiver (MLP that takes a message and predicts an image)\n","class Receiver(nn.Module):\n","    def __init__(self, message_size, action_size):\n","        super(Receiver, self).__init__()\n","        self.fc1 = nn.Linear(message_size, 128)\n","        self.fc2 = nn.Linear(128, action_size)\n","\n","    def forward(self, message):\n","        x = torch.relu(self.fc1(message))\n","        action_logits = self.fc2(x)\n","        return action_logits\n","\n","# Initialize models, loss function, and optimizers\n","sender = Sender(MESSAGE_SIZE)\n","receiver = Receiver(MESSAGE_SIZE, ACTION_SIZE)\n","\n","criterion = nn.CrossEntropyLoss()\n","sender_optimizer = optim.Adam(sender.parameters(), lr=LEARNING_RATE)\n","receiver_optimizer = optim.Adam(receiver.parameters(), lr=LEARNING_RATE)\n","\n","# Training loop\n","for epoch in range(NUM_EPOCHS):\n","    sender_optimizer.zero_grad()\n","    receiver_optimizer.zero_grad()\n","\n","    # Randomly select a batch of images\n","    selected_indices = (1,2,3,4,5)\n","    selected_image = images[selected_indices[0]].unsqueeze(0)  # Add batch dimension\n","    selected_label = labels[selected_indices[0]]\n","\n","    # Forward pass through Sender\n","    messages = sender(selected_image)\n","\n","    # Forward pass through Receiver\n","    action_logits = receiver(messages)\n","\n","    # Compute loss\n","    loss = criterion(action_logits, torch.tensor([selected_label]))\n","\n","    # Backward pass and optimization\n","    loss.backward()\n","    sender_optimizer.step()\n","    receiver_optimizer.step()\n","\n","    # Print progress every 5 epochs\n","    if (epoch + 1) % 5 == 0:\n","        print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Loss: {loss.item():.4f}\")\n","\n","# Test the Receiver's performance\n","correct = 0\n","for i in range(5):\n","    with torch.no_grad():\n","        selected_image = images[i].unsqueeze(0)  # Add batch dimension\n","        message = sender(selected_image)\n","        action_logits = receiver(message)\n","        predicted_label = torch.argmax(action_logits, dim=1).item()\n","        print(f\"Image {i}: Predicted Label {predicted_label}, True Label {labels[i]}\")\n","        if predicted_label == labels[i]:\n","            correct += 1\n","\n","accuracy = correct / 5\n","print(f\"\\nReceiver Accuracy: {accuracy * 100:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":307},"id":"C-VUrycs8ZXr","executionInfo":{"status":"ok","timestamp":1740015623428,"user_tz":360,"elapsed":4585,"user":{"displayName":"Alan Mauricio Camargo Hernandez","userId":"09753390928466343821"}},"outputId":"993450a2-afa8-4fa4-fe39-75a46f7453ae"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 5 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 5/10, Loss: 0.3256\n","Epoch 10/10, Loss: 0.0265\n","Image 0: Predicted Label 2, True Label 1\n","Image 1: Predicted Label 2, True Label 2\n","Image 2: Predicted Label 2, True Label 3\n","Image 3: Predicted Label 2, True Label 4\n","Image 4: Predicted Label 2, True Label 5\n","\n","Receiver Accuracy: 20.00%\n"]}]},{"cell_type":"markdown","source":["# emojis\n"],"metadata":{"id":"Tf1hIuCVGP-n"}},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","\n","# Cargar modelo ligero (SLM)\n","model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # Modelo optimizado para chat\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(model_name)\n","\n","# Función para traducir texto a emojis\n","def text_to_emoji(text):\n","    prompt = f\"Traduce esta frase a emojis:\\nTexto: {text}\\nEmoji:\"\n","\n","    inputs = tokenizer(prompt, return_tensors=\"pt\")\n","    with torch.no_grad():\n","        output = model.generate(**inputs, max_length=50, do_sample=True, top_k=40, top_p=0.9)\n","\n","    response = tokenizer.decode(output[0], skip_special_tokens=True)\n","    return response\n","\n","# Ejemplo de uso\n","print(text_to_emoji(\"Estoy feliz porque es viernes\"))\n","print(text_to_emoji(\"Voy a comer pizza esta noche\"))\n","print(text_to_emoji(\"Hoy llueve mucho\"))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":399,"referenced_widgets":["e43d4bd1a5a34cc5a3c0322c0cea7a6c","cd7e713d89e04116952a537ab5aea3f2","8ee207bbbc314b55bbcf56c135106fef","4efb059c10b74617862db3dfd11b1c9f","362fb74126cf4824abe1b430dcbd9977","f88c62a7a69643aea2a5219ae032d0da","35527e77ba8a4081875213067f05dd7a","b9f332c9487c4f42879f3a6cc4daa264","fd9a01943ea6409399dbeaf9b9d47677","597ea38b6b8d4df89f58fcde4cc05514","5731e1ce713b4c2fadc9eef9bb2bdf90","df066e378da04e079dfe4a35e4fea2b5","f699a75a208743bd9bc9ec979eda951a","ea0a4b4471e14096ab1af7db944c5e7e","7bb4e9ea18fb4a49989fd8ee5f6c0629","93ebe5e8405e447f997912edbaf557ad","1a400a8b608346bcb4cb969411dc1ea3","ceedcc1f559541f484ac828f5774f829","50ad23f3188b4109b58f9c9556a82b98","1479efeb44234a3bab144ca0340a14df","b7a231f2189542ceb542ba57576c268d","341a7d1b2b25499babe1ef3b49716cf7","c16bab710a874dc4b300f3563573c104","c939e59b5de74230a18bff6bc4f1a498","50cb95086d794affbbabefa4fd0910ac","669ef4b52336483b90a5e595fd91d2c4","11606f19947d4cb48a0bf9c153ead90b","9e64d3ca440a4bc2b99049685d039d9c","abc76edaab684eb99bda1d809dd5e0f6","937dc66f4f85402599cfa67b23443dee","614bcc87ef8441089cc0992e9d0a3a01","d40fe870dbf4444fb28768c0c69aac56","0418effdb5ba499f870f5a566778b43f","bcee996b9655449b8b39b922bc5d95e1","d680ebe3f91144938dab67ee09f97f08","1fbe785de9824decb70f450adfb01e77","eb2e46ec32c84c0d9b055b4ec239ecd0","974ff4c7462f46b78bcdafc815d7c3e5","ab083f7b55854932a82c9e9b36ab71f0","252d35466e9547899333174373109945","651e1020c2b8475f972bf0e1adefe01a","70372f450f3642fba8b52795f8184717","0a603e647f814c34ae162e297c3a8d50","4e19c3dd07024f80994adeb8c55845e8"]},"id":"biVttS-GGPVO","executionInfo":{"status":"ok","timestamp":1740018241740,"user_tz":360,"elapsed":42969,"user":{"displayName":"Alan Mauricio Camargo Hernandez","userId":"09753390928466343821"}},"outputId":"d3a8975d-1c29-4070-ec3a-1b378f77967b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e43d4bd1a5a34cc5a3c0322c0cea7a6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df066e378da04e079dfe4a35e4fea2b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c16bab710a874dc4b300f3563573c104"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcee996b9655449b8b39b922bc5d95e1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Traduce esta frase a emojis:\n","Texto: Estoy feliz porque es viernes\n","Emoji: 💃🏻‍♀️\n","Texto: Estoy feliz porque\n","Traduce esta frase a emojis:\n","Texto: Voy a comer pizza esta noche\n","Emoji: 🍕\n","Emojis:\n","Emoji: 🍕\n","Traduce esta frase a emojis:\n","Texto: Hoy llueve mucho\n","Emoji: Foto de un chico con lechiguinas en la boca\n","\n","8. \"Acerca\n"]}]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","\n","# Cargar modelo de lenguaje (SLM)\n","model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"   # Alternativamente \"distilgpt2\" o \"TinyLlama\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(model_name)\n","\n","# Función para traducir emojis a texto\n","def emoji_to_text(emoji_string):\n","    prompt = f\"Traduce estos emojis a texto:\\nEmojis: {emoji_string}\\nTexto:\"\n","\n","    inputs = tokenizer(prompt, return_tensors=\"pt\")\n","    with torch.no_grad():\n","        output = model.generate(**inputs, max_length=50, do_sample=True, top_k=40, top_p=0.9)\n","\n","    response = tokenizer.decode(output[0], skip_special_tokens=True)\n","    return response\n","\n","# Ejemplos de uso\n","print(emoji_to_text(\"😊🎉🍻\"))\n","print(emoji_to_text(\"🍕🌙\"))\n","print(emoji_to_text(\"🌧️☔\"))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z96s4yjrHk8z","executionInfo":{"status":"ok","timestamp":1740018314768,"user_tz":360,"elapsed":41585,"user":{"displayName":"Alan Mauricio Camargo Hernandez","userId":"09753390928466343821"}},"outputId":"40a6f242-f2c3-4448-e837-3c0fa702e82b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traduce estos emojis a texto:\n","Emojis: 😊🎉🍻\n","Texto: Ola, quero falar sobre isso que realmente lindo,\n","Traduce estos emojis a texto:\n","Emojis: 🍕🌙\n","Texto: ¡Vengan al café!\n","\n","5. Enviar imágenes:\n","Traduce estos emojis a texto:\n","Emojis: 🌧️☔\n","Texto: Quizás no pueda, pero lo sé que estoy haciendo.\n","\n","3.\n"]}]},{"cell_type":"code","source":["!watch -n 1 free -m"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"danqrs2pOI9x","executionInfo":{"status":"ok","timestamp":1740019201045,"user_tz":360,"elapsed":49290,"user":{"displayName":"Alan Mauricio Camargo Hernandez","userId":"09753390928466343821"}},"outputId":"1cefc427-a164-41c0-a303-f6eda6e74909"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?1l\u001b>"]}]},{"cell_type":"code","source":["import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","# Elegir un modelo sin restricciones\n","model_name = \"mistralai/Mistral-7B-Instruct\"  # Modelo abierto\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n","\n","# Función para obtener respuesta del modelo\n","def get_response(prompt):\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n","    outputs = model.generate(**inputs, max_length=200)\n","    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return response\n","\n","# Iniciar el juego\n","contexto = \"Eres un aventurero en un mundo medieval lleno de magia y peligros.\"\n","while True:\n","    accion = input(\">> \")  # El jugador ingresa su acción\n","    prompt = f\"{contexto}\\nJugador: {accion}\\nNarrador:\"\n","    respuesta = get_response(prompt)\n","    print(respuesta)\n","    contexto += f\"\\nJugador: {accion}\\nNarrador: {respuesta}\"  # Se actualiza el contexto del juego\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":678},"id":"Z_qU4_P9OHty","executionInfo":{"status":"error","timestamp":1740019452837,"user_tz":360,"elapsed":528,"user":{"displayName":"Alan Mauricio Camargo Hernandez","userId":"09753390928466343821"}},"outputId":"4e3c676f-4d60-4f42-ac43-42cdf2e0c136"},"execution_count":null,"outputs":[{"output_type":"error","ename":"OSError","evalue":"mistralai/Mistral-7B-Instruct is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/mistralai/Mistral-7B-Instruct/resolve/main/tokenizer_config.json","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0;31m# Repo not found or gated => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1375\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1293\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1295\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    279\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    453\u001b[0m             )\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-67b696fc-2c656f0a60a2f9683c74c268;9995988f-0134-4b85-bcde-ce6b36b7a288)\n\nRepository Not Found for url: https://huggingface.co/mistralai/Mistral-7B-Instruct/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-55b79d556f5b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Elegir un modelo sin restricciones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mistralai/Mistral-7B-Instruct\"\u001b[0m  \u001b[0;31m# Modelo abierto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m         \u001b[0mtokenizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0mcommit_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m     resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m         ) from e\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    427\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: mistralai/Mistral-7B-Instruct is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"]}]},{"cell_type":"code","source":["pip install transformers dotenv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o1m26VLMSIDt","executionInfo":{"status":"ok","timestamp":1740020174881,"user_tz":360,"elapsed":7278,"user":{"displayName":"Alan Mauricio Camargo Hernandez","userId":"09753390928466343821"}},"outputId":"aa583c6a-2d37-4a1c-d1d9-8b39a3c79727"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n","Collecting dotenv\n","  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Collecting python-dotenv (from dotenv)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n","Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n","Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Installing collected packages: python-dotenv, dotenv\n","Successfully installed dotenv-0.9.9 python-dotenv-1.0.1\n"]}]},{"cell_type":"code","source":["import os\n","import json\n","import time\n","import requests\n","from typing import Dict, List, Any\n","from dotenv import load_dotenv\n","\n","# Cargar variables de entorno (.env)\n","load_dotenv()\n","\n","# Estructura de datos para el juego\n","class GameState:\n","    def __init__(self):\n","        self.player = {\n","            \"name\": \"\",\n","            \"class\": \"\",\n","            \"level\": 1,\n","            \"hp\": 100,\n","            \"max_hp\": 100,\n","            \"inventory\": [],\n","            \"location\": \"pueblo_inicial\",\n","            \"quests\": [],\n","            \"skills\": []\n","        }\n","        self.world = {\n","            \"current_location\": \"pueblo_inicial\",\n","            \"discovered_locations\": [\"pueblo_inicial\"],\n","            \"npc_relations\": {},\n","            \"world_state\": {\"main_quest_stage\": 0}\n","        }\n","        self.game_log = []\n","\n","    def to_context(self) -> str:\n","        \"\"\"Convierte el estado del juego a un contexto para el LLM\"\"\"\n","        context = f\"\"\"\n","Estado actual del juego:\n","Jugador: {self.player['name']}, {self.player['class']} nivel {self.player['level']}\n","Salud: {self.player['hp']}/{self.player['max_hp']}\n","Ubicación: {self.world['current_location']}\n","Inventario: {', '.join(self.player['inventory']) if self.player['inventory'] else 'Vacío'}\n","Misiones activas: {', '.join(self.player['quests']) if self.player['quests'] else 'Ninguna'}\n","\"\"\"\n","        return context\n","\n","    def log_interaction(self, player_action: str, gm_response: str) -> None:\n","        \"\"\"Registra interacciones en el log del juego\"\"\"\n","        self.game_log.append({\n","            \"timestamp\": time.time(),\n","            \"player_action\": player_action,\n","            \"gm_response\": gm_response\n","        })\n","\n","# Cliente para HuggingFace Inference API\n","class HuggingFaceClient:\n","    def __init__(self, model_name=\"HuggingFaceH4/zephyr-7b-beta\", api_key=None):\n","        self.model_name = model_name\n","        self.api_key = api_key or os.getenv(\"HF_API_KEY\")\n","        if not self.api_key:\n","            raise ValueError(\"Se requiere una API key de HuggingFace. Configúrala como HF_API_KEY en tus variables de entorno.\")\n","        self.api_url = f\"https://api-inference.huggingface.co/models/{model_name}\"\n","\n","    def generate(self, prompt, system_prompt=None, temperature=0.7, max_tokens=500):\n","        \"\"\"Genera texto usando HuggingFace Inference API\"\"\"\n","        # Formatear el prompt para modelos tipo chat\n","        if system_prompt:\n","            messages = [\n","                {\"role\": \"system\", \"content\": system_prompt},\n","                {\"role\": \"user\", \"content\": prompt}\n","            ]\n","            # Convertir a formato de texto para modelos que no soportan chat\n","            formatted_prompt = f\"<|system|>\\n{system_prompt}\\n<|user|>\\n{prompt}\\n<|assistant|>\"\n","        else:\n","            formatted_prompt = prompt\n","\n","        headers = {\"Authorization\": f\"Bearer {self.api_key}\"}\n","\n","        # Intentar primero con formato de chat\n","        try:\n","            chat_payload = {\n","                \"inputs\": messages,\n","                \"parameters\": {\n","                    \"temperature\": temperature,\n","                    \"max_new_tokens\": max_tokens,\n","                    \"return_full_text\": False\n","                }\n","            }\n","            response = requests.post(\n","                self.api_url,\n","                headers=headers,\n","                json=chat_payload,\n","                timeout=30\n","            )\n","\n","            # Si no soporta formato de chat, usar formato de texto\n","            if response.status_code == 400:\n","                raise ValueError(\"Modelo no soporta formato de chat\")\n","\n","            response.raise_for_status()\n","            result = response.json()\n","\n","            if isinstance(result, list) and len(result) > 0:\n","                return result[0].get(\"generated_text\", \"\")\n","            elif isinstance(result, dict):\n","                return result.get(\"generated_text\", \"\")\n","            return \"Error: formato de respuesta inesperado.\"\n","\n","        except Exception as chat_error:\n","            # Fallback a formato de texto si el chat no funciona\n","            try:\n","                text_payload = {\n","                    \"inputs\": formatted_prompt,\n","                    \"parameters\": {\n","                        \"temperature\": temperature,\n","                        \"max_new_tokens\": max_tokens,\n","                        \"return_full_text\": False\n","                    }\n","                }\n","                response = requests.post(\n","                    self.api_url,\n","                    headers=headers,\n","                    json=text_payload,\n","                    timeout=30\n","                )\n","                response.raise_for_status()\n","                result = response.json()\n","\n","                if isinstance(result, list) and len(result) > 0:\n","                    return result[0].get(\"generated_text\", \"\")\n","                elif isinstance(result, dict):\n","                    return result.get(\"generated_text\", \"\")\n","                return \"Error: formato de respuesta inesperado.\"\n","\n","            except Exception as e:\n","                print(f\"Error al llamar a HuggingFace: {e}\")\n","                return f\"Error de conexión con el modelo. Detalles: {str(e)[:100]}...\"\n","\n","class GameMaster:\n","    def __init__(self, game_settings: Dict[str, Any], model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\"):\n","        self.settings = game_settings\n","        self.world_lore = game_settings[\"world_lore\"]\n","        self.game_rules = game_settings[\"game_rules\"]\n","        self.llm_client = HuggingFaceClient(model_name=model_name)\n","\n","    def get_response(self, game_state: GameState, player_action: str) -> str:\n","        \"\"\"Obtiene respuesta del GM LLM basado en la acción del jugador\"\"\"\n","        system_prompt = self._build_context(game_state)\n","        user_prompt = f\"Acción del jugador: {player_action}\"\n","\n","        response = self.llm_client.generate(\n","            prompt=user_prompt,\n","            system_prompt=system_prompt,\n","            temperature=0.7,\n","            max_tokens=500\n","        )\n","\n","        # Limpiar respuestas potencialmente problemáticas\n","        response = self._clean_response(response)\n","        return response\n","\n","    def _build_context(self, game_state: GameState) -> str:\n","        \"\"\"Construye el contexto para el GM\"\"\"\n","        context = f\"\"\"\n","Eres el Game Master de un RPG de texto en español. Tu trabajo es narrar la historia, gestionar las reglas\n","y representar a todos los personajes no jugadores (NPCs) del mundo.\n","\n","CONFIGURACIÓN DEL MUNDO:\n","{self.world_lore}\n","\n","REGLAS DEL JUEGO:\n","{self.game_rules}\n","\n","{game_state.to_context()}\n","\n","Por favor, responde a las acciones del jugador de forma narrativa y emotiva.\n","Tu respuesta debe incluir:\n","1. Narración descriptiva de lo que ocurre\n","2. Diálogo de NPCs si corresponde\n","3. Actualización de estado del jugador si es necesario\n","4. Opciones o pistas sobre posibles acciones futuras\n","\n","IMPORTANTE: Responde SIEMPRE en español y sólo genera la narración del Game Master, no incluyas etiquetas como\n","\"Game Master:\" o similar. No hagas preguntas meta sobre el juego.\n","\"\"\"\n","        return context\n","\n","    def _clean_response(self, response):\n","        \"\"\"Limpia la respuesta del modelo para eliminar artefactos no deseados\"\"\"\n","        # Eliminar prefijos comunes que algunos modelos añaden\n","        prefixes = [\n","            \"<|assistant|>\", \"Assistant:\", \"GameMaster:\", \"GM:\",\n","            \"Game Master:\", \"Narrador:\", \"Respuesta:\", \"\\n\\n\"\n","        ]\n","\n","        for prefix in prefixes:\n","            if response.startswith(prefix):\n","                response = response[len(prefix):].strip()\n","\n","        # Eliminar citas de usuario que a veces se repiten\n","        if \"Acción del jugador:\" in response:\n","            response = response.split(\"Acción del jugador:\")[0].strip()\n","\n","        return response\n","\n","class AIPlayer:\n","    def __init__(self, player_settings: Dict[str, Any], model_name=\"google/gemma-7b-it\"):\n","        self.character_concept = player_settings[\"character_concept\"]\n","        self.personality = player_settings[\"personality\"]\n","        self.goals = player_settings[\"goals\"]\n","        self.llm_client = HuggingFaceClient(model_name=model_name)\n","\n","    def get_action(self, game_state: GameState, gm_response: str) -> str:\n","        \"\"\"Genera la siguiente acción del jugador AI\"\"\"\n","        system_prompt = self._build_context(game_state)\n","        user_prompt = f\"Situación actual: {gm_response}\\n\\n¿Qué haces ahora?\"\n","\n","        response = self.llm_client.generate(\n","            prompt=user_prompt,\n","            system_prompt=system_prompt,\n","            temperature=0.9,\n","            max_tokens=150\n","        )\n","\n","        # Limpiar respuestas potencialmente problemáticas\n","        response = self._clean_response(response)\n","        return response\n","\n","    def _build_context(self, game_state: GameState) -> str:\n","        \"\"\"Construye el contexto para el jugador AI\"\"\"\n","        context = f\"\"\"\n","Eres un personaje jugador en un RPG de texto en español. Actúas como {game_state.player['name']},\n","un {game_state.player['class']} con la siguiente personalidad:\n","\n","CONCEPTO DEL PERSONAJE:\n","{self.character_concept}\n","\n","PERSONALIDAD:\n","{self.personality}\n","\n","OBJETIVOS:\n","{self.goals}\n","\n","{game_state.to_context()}\n","\n","Por favor, genera una acción que sea:\n","1. Consistente con tu personaje\n","2. Reactiva a la situación descrita\n","3. Creativa y específica (no solo \"ataco\" sino \"ataco con mi espada apuntando a su pierna izquierda\")\n","4. Usa primera persona\n","\n","IMPORTANTE: Responde SIEMPRE en español y genera SOLAMENTE la acción del personaje, sin añadir etiquetas\n","como \"Acción:\" o similar. Responde como si fueras el personaje hablando en primera persona.\n","\"\"\"\n","        return context\n","\n","    def _clean_response(self, response):\n","        \"\"\"Limpia la respuesta del modelo para eliminar artefactos no deseados\"\"\"\n","        # Eliminar prefijos comunes que algunos modelos añaden\n","        prefixes = [\n","            \"<|assistant|>\", \"Assistant:\", \"Jugador:\", \"Player:\",\n","            \"Acción:\", \"Elric:\", \"Respuesta:\", \"\\n\\n\"\n","        ]\n","\n","        for prefix in prefixes:\n","            if response.startswith(prefix):\n","                response = response[len(prefix):].strip()\n","\n","        # Eliminar citas de la situación que a veces se repiten\n","        if \"Situación actual:\" in response:\n","            response = response.split(\"Situación actual:\")[0].strip()\n","\n","        return response\n","\n","def run_game_session(num_turns: int = 10):\n","    \"\"\"Ejecuta una sesión de juego entre el GM y el jugador AI\"\"\"\n","    # Modelos recomendados de HuggingFace (gratuitos con API key)\n","    gm_model = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"  # Buen modelo para narración\n","    player_model = \"google/gemma-7b-it\"  # Buen modelo para decisiones\n","\n","    # Configuración inicial\n","    game_settings = {\n","        \"world_lore\": \"\"\"\n","        El mundo de Eldoria es un reino de fantasía medieval con elementos mágicos.\n","        Tras la caída del Rey Brujo, el reino está fragmentado en facciones que luchan por el poder.\n","        La magia es rara pero poderosa, controlada principalmente por la Academia Arcana.\n","        Criaturas místicas habitan los bosques y montañas, mientras que antiguas ruinas esconden tesoros olvidados.\n","        El pueblo inicial, Villarroble, es una pequeña aldea en el borde de un gran bosque. Tiene una posada llamada\n","        \"El Dragón Dormido\", una herrería, un pequeño mercado y un templo a los dioses antiguos.\n","        \"\"\",\n","        \"game_rules\": \"\"\"\n","        - Combate: Las acciones de combate tienen probabilidad de éxito basada en estadísticas del personaje.\n","          Ataques mágicos: d20 + INT > dificultad\n","          Ataques físicos: d20 + STR > dificultad\n","          Esquivar: d20 + DEX > dificultad\n","        - Magia: El jugador aprende hechizos a medida que sube de nivel o encuentra tomos antiguos.\n","          Hechizos iniciales: Proyectil Arcano (daño), Luz (utilidad), Escudo Arcano (defensa)\n","        - Exploración: Nuevas áreas se desbloquean cumpliendo misiones o encontrando pistas.\n","        - Interacción: Los NPCs reaccionan según su disposición hacia el jugador (amigable, neutral, hostil).\n","        - Progresión: El jugador gana experiencia al completar objetivos, resolver conflictos y derrotar enemigos.\n","          Cada nivel otorga más vida, nuevas habilidades y mejora de atributos.\n","        \"\"\"\n","    }\n","\n","    player_settings = {\n","        \"character_concept\": \"Un joven mago que busca vengar la muerte de su mentor Archmago Thorne\",\n","        \"personality\": \"Curioso, determinado, algo impulsivo pero con un fuerte sentido de justicia. Elric tiene pesadillas recurrentes sobre la noche en que encontró a su mentor muerto, con extraños símbolos arcanos dibujados con sangre a su alrededor.\",\n","        \"goals\": \"Descubrir quién mató a tu mentor, dominar la magia arcana prohibida que tu mentor te ocultaba, proteger a los inocentes de las conspiraciones que sientes que están ocurriendo en las sombras del reino.\"\n","    }\n","\n","    # Inicializar juego\n","    game_state = GameState()\n","    game_state.player[\"name\"] = \"Elric\"\n","    game_state.player[\"class\"] = \"Mago Aprendiz\"\n","    game_state.player[\"skills\"] = [\"Proyectil Arcano\", \"Luz\", \"Escudo Arcano\"]\n","    game_state.player[\"inventory\"] = [\"Grimorio básico\", \"Daga ceremonial\", \"Poción de salud (2)\"]\n","\n","    try:\n","        gm = GameMaster(game_settings, model_name=gm_model)\n","        player = AIPlayer(player_settings, model_name=player_model)\n","\n","        # Mensaje inicial del GM\n","        print(\"Iniciando juego RPG con modelos HuggingFace...\\n\")\n","        initial_prompt = \"\"\"\n","        Comienza la aventura describiendo la situación inicial.\n","        El joven mago Elric se encuentra en la posada \"El Dragón Dormido\" en el pueblo de Villarroble.\n","        Han pasado tres semanas desde que encontró a su mentor asesinado. Está siguiendo pistas sobre\n","        un misterioso comerciante que visitó a su mentor la noche de su muerte.\n","        \"\"\"\n","        gm_response = gm.get_response(game_state, initial_prompt)\n","        print(f\"=== GAME MASTER ===\\n{gm_response}\\n\")\n","\n","        # Ciclo principal del juego\n","        for turn in range(num_turns):\n","            print(f\"--- TURNO {turn+1} ---\")\n","            # El jugador AI decide su acción\n","            player_action = player.get_action(game_state, gm_response)\n","            print(f\"=== ELRIC ===\\n{player_action}\\n\")\n","\n","            # El GM responde\n","            gm_response = gm.get_response(game_state, player_action)\n","            print(f\"=== GAME MASTER ===\\n{gm_response}\\n\")\n","\n","            # Registrar la interacción\n","            game_state.log_interaction(player_action, gm_response)\n","\n","            # Breve pausa entre turnos para mejorar la experiencia de lectura\n","            time.sleep(0.5)\n","\n","        # Guardar el log del juego\n","        with open(\"rpg_session_log.json\", \"w\", encoding=\"utf-8\") as f:\n","            json.dump(game_state.game_log, f, ensure_ascii=False, indent=2)\n","\n","        print(\"Sesión de juego completada y guardada en 'rpg_session_log.json'.\")\n","\n","    except Exception as e:\n","        print(f\"\\nError durante la ejecución: {e}\")\n","        print(\"\\nAsegúrate de tener configurada tu API key de HuggingFace como variable de entorno 'HF_API_KEY'\")\n","        print(\"o crea un archivo .env con el contenido: HF_API_KEY=tu_clave_api\")\n","\n","if __name__ == \"__main__\":\n","    run_game_session(10)  # Ejecutar 10 turnos de juego"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aoBXP47cRVoe","executionInfo":{"status":"ok","timestamp":1740020191520,"user_tz":360,"elapsed":75,"user":{"displayName":"Alan Mauricio Camargo Hernandez","userId":"09753390928466343821"}},"outputId":"30236eec-ce8f-4e2d-e9cb-67df74d51892"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Error durante la ejecución: Se requiere una API key de HuggingFace. Configúrala como HF_API_KEY en tus variables de entorno.\n","\n","Asegúrate de tener configurada tu API key de HuggingFace como variable de entorno 'HF_API_KEY'\n","o crea un archivo .env con el contenido: HF_API_KEY=tu_clave_api\n"]}]},{"cell_type":"code","source":["# Emoji Communication Game - Lenguaje Emergente\n","# Compatible con Google Colab y Hugging Face\n","\n","# Instalar dependencias\n","!pip install emoji transformers datasets matplotlib scikit-learn pandas numpy ipywidgets pillow\n","\n","import os\n","import random\n","import json\n","import emoji\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from collections import defaultdict, Counter\n","from IPython.display import display, HTML, clear_output\n","from PIL import Image, ImageDraw, ImageFont\n","import ipywidgets as widgets\n","from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n","from google.colab import files\n","\n","# Configurar visualizaciones\n","plt.style.use('ggplot')\n","sns.set(style=\"whitegrid\")\n","\n","# Cargar modelo de embeddings de Hugging Face para análisis semántico\n","from transformers import AutoTokenizer, AutoModel\n","import torch\n","\n","def load_sentence_model():\n","    tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n","    model = AutoModel.from_pretrained(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n","    return tokenizer, model\n","\n","# Función para obtener embeddings de texto\n","def get_embeddings(texts, tokenizer, model):\n","    encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n","    with torch.no_grad():\n","        model_output = model(**encoded_input)\n","    embeddings = model_output.last_hidden_state.mean(dim=1)\n","    return embeddings\n","\n","class EmojiCommunicationGame:\n","    def __init__(self):\n","        # Datos del juego\n","        self.image_categories = {\n","            \"animales\": [\"🐶\", \"🐱\", \"🐯\", \"🦁\", \"🐮\", \"🐷\", \"🐸\", \"🐦\", \"🦊\", \"🐢\"],\n","            \"comida\": [\"🍎\", \"🍕\", \"🍔\", \"🍦\", \"🍰\", \"🍺\", \"🍗\", \"🥑\", \"🍓\", \"🍳\"],\n","            \"lugares\": [\"🏠\", \"🏢\", \"⛰️\", \"🏖️\", \"🌋\", \"🏛️\", \"🏞️\", \"🌆\", \"🏕️\", \"🏝️\"],\n","            \"transporte\": [\"🚗\", \"✈️\", \"🚂\", \"🚢\", \"🚁\", \"🚲\", \"🛵\", \"🚌\", \"🚜\", \"🛸\"],\n","            \"clima\": [\"☀️\", \"🌧️\", \"❄️\", \"🌈\", \"⚡\", \"🌪️\", \"☁️\", \"🌫️\", \"🌊\", \"🔥\"]\n","        }\n","\n","        # Cargar modelos de Hugging Face\n","        print(\"Cargando modelos de Hugging Face...\")\n","        self.sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n","        self.tokenizer, self.model = load_sentence_model()\n","\n","        # Configuración del juego\n","        self.current_round = 0\n","        self.max_rounds = 10\n","        self.score = 0\n","        self.communication_log = []\n","        self.current_target = None\n","        self.current_options = []\n","        self.emoji_usage_stats = defaultdict(int)\n","        self.emoji_success_rate = defaultdict(lambda: [0, 0])  # [éxitos, total]\n","\n","        # Cargar historial si existe\n","        self.game_history = self.load_game_history()\n","\n","        # Crear UI con ipywidgets\n","        self.create_widgets()\n","\n","    def create_widgets(self):\n","        # Widget contenedor principal\n","        self.main_container = widgets.VBox([])\n","\n","        # Título\n","        self.title = widgets.HTML(\"<h1 style='text-align:center;'>EmojiCom - Comunicación Emergente</h1>\")\n","\n","        # Información del juego\n","        self.game_info = widgets.HBox([\n","            widgets.Label(\"Ronda: 0/10\"),\n","            widgets.Label(\"Puntuación: 0\")\n","        ])\n","\n","        # Área de juego\n","        self.target_display = widgets.Output()\n","\n","        # Selector de categoría\n","        self.category_selector = widgets.RadioButtons(\n","            options=list(self.image_categories.keys()),\n","            description='Categoría:',\n","            layout={'width': 'max-content'}\n","        )\n","        self.category_selector.observe(self.update_emoji_palette, names='value')\n","\n","        # Paleta de emojis\n","        self.emoji_palette = widgets.HBox([])\n","        self.update_emoji_palette()\n","\n","        # Entrada de mensaje\n","        self.message_input = widgets.Text(\n","            placeholder='Escribe tu mensaje de emojis',\n","            description='Mensaje:',\n","            layout=widgets.Layout(width='50%')\n","        )\n","\n","        # Botón de enviar\n","        self.send_button = widgets.Button(\n","            description='Enviar mensaje',\n","            button_style='info'\n","        )\n","        self.send_button.on_click(self.send_emoji_message)\n","\n","        # Área de recepción\n","        self.message_display = widgets.HTML(\"\")\n","        self.options_display = widgets.GridBox(\n","            children=[],\n","            layout=widgets.Layout(\n","                grid_template_columns='repeat(2, 200px)',\n","                grid_gap='10px'\n","            )\n","        )\n","\n","        # Botones de control\n","        self.start_button = widgets.Button(\n","            description='Iniciar juego',\n","            button_style='success'\n","        )\n","        self.start_button.on_click(self.start_game)\n","\n","        self.stats_button = widgets.Button(\n","            description='Ver estadísticas',\n","            button_style='warning'\n","        )\n","        self.stats_button.on_click(self.show_statistics)\n","\n","        # Armar la interfaz\n","        self.game_layout = widgets.VBox([\n","            self.title,\n","            self.game_info,\n","            widgets.HBox([\n","                # Panel de emisor\n","                widgets.VBox([\n","                    widgets.HTML(\"<h3>Panel del Emisor</h3>\"),\n","                    self.target_display,\n","                    self.category_selector,\n","                    self.emoji_palette,\n","                    widgets.HBox([self.message_input, self.send_button])\n","                ], layout=widgets.Layout(border='1px solid #ddd', padding='10px', width='50%')),\n","\n","                # Panel de receptor\n","                widgets.VBox([\n","                    widgets.HTML(\"<h3>Panel del Receptor</h3>\"),\n","                    self.message_display,\n","                    self.options_display\n","                ], layout=widgets.Layout(border='1px solid #ddd', padding='10px', width='50%'))\n","            ]),\n","            widgets.HBox([self.start_button, self.stats_button])\n","        ])\n","\n","        # Mostrar la interfaz\n","        display(self.game_layout)\n","\n","    def update_emoji_palette(self, change=None):\n","        category = self.category_selector.value\n","        emoji_buttons = []\n","\n","        for emoji_char in self.image_categories[category]:\n","            button = widgets.Button(\n","                description=emoji_char,\n","                layout=widgets.Layout(width='40px', height='40px')\n","            )\n","            button.on_click(lambda b, e=emoji_char: self.add_emoji_to_message(e))\n","            emoji_buttons.append(button)\n","\n","        self.emoji_palette.children = emoji_buttons\n","\n","    def add_emoji_to_message(self, emoji_char):\n","        current_text = self.message_input.value\n","        # Limitar a 5 emojis aproximadamente\n","        if len(current_text) < 10:\n","            self.message_input.value += emoji_char\n","\n","    def emoji_to_image(self, emoji_char, size=(150, 150)):\n","        \"\"\"Convierte un emoji a una imagen usando PIL\"\"\"\n","        img = Image.new('RGBA', size, color=(255, 255, 255, 255))\n","        d = ImageDraw.Draw(img)\n","        # Intentar cargar una fuente que soporte emojis (esto puede variar según el entorno)\n","        try:\n","            font_size = min(size) - 20\n","            font = ImageFont.truetype(\"arial.ttf\", font_size)\n","        except:\n","            # Fallback si no se encuentra la fuente\n","            try:\n","                font = ImageFont.load_default()\n","            except:\n","                # Si todo falla, devolver una representación de texto\n","                return f\"<div style='font-size:72px;text-align:center;'>{emoji_char}</div>\"\n","\n","        # Dibujar el emoji centrado\n","        w, h = d.textsize(emoji_char, font=font)\n","        d.text(((size[0]-w)/2, (size[1]-h)/2), emoji_char, fill=(0, 0, 0), font=font)\n","\n","        return img\n","\n","    def start_game(self, b=None):\n","        self.current_round = 0\n","        self.score = 0\n","        self.communication_log = []\n","        self.next_round()\n","\n","    def next_round(self):\n","        if self.current_round >= self.max_rounds:\n","            self.end_game()\n","            return\n","\n","        self.current_round += 1\n","        self.game_info.children[0].value = f\"Ronda: {self.current_round}/{self.max_rounds}\"\n","\n","        # Seleccionar una categoría al azar\n","        category = random.choice(list(self.image_categories.keys()))\n","\n","        # Generar \"imágenes\" (emojis como placeholders)\n","        all_emojis = self.get_all_emojis()\n","        options = random.sample(all_emojis, 4)\n","        self.current_target = options[0]\n","        self.current_options = options.copy()\n","        random.shuffle(self.current_options)\n","\n","        # Mostrar imagen objetivo al Emisor\n","        with self.target_display:\n","            clear_output(wait=True)\n","            display(HTML(f\"<h2 style='text-align:center;'>Objetivo a comunicar</h2>\"))\n","            display(HTML(f\"<div style='font-size:100px;text-align:center;'>{self.current_target}</div>\"))\n","\n","        # Mostrar opciones al Receptor\n","        option_buttons = []\n","        for i, emoji_option in enumerate(self.current_options):\n","            option_html = f\"<div style='font-size:72px;text-align:center;'>{emoji_option}</div>\"\n","            button = widgets.Button(\n","                description=f'Opción {i+1}',\n","                disabled=True,\n","                layout=widgets.Layout(width='180px', height='180px')\n","            )\n","            button.option_emoji = emoji_option\n","            button.option_index = i\n","            button.on_click(lambda b: self.check_answer(b.option_index))\n","\n","            card = widgets.VBox([\n","                widgets.HTML(option_html),\n","                button\n","            ], layout=widgets.Layout(border='1px solid #ddd', padding='5px'))\n","            option_buttons.append(card)\n","\n","        self.options_display.children = option_buttons\n","\n","        # Limpiar mensaje y habilitar envío\n","        self.message_input.value = \"\"\n","        self.message_display.value = \"<h3>Esperando mensaje...</h3>\"\n","        self.send_button.disabled = False\n","\n","    def send_emoji_message(self, b=None):\n","        message = self.message_input.value\n","        if not message or len(message.strip()) == 0:\n","            self.message_display.value = \"<p style='color:red;'>Error: Debes enviar al menos un emoji</p>\"\n","            return\n","\n","        # Mostrar mensaje al receptor\n","        self.message_display.value = f\"<h3>Mensaje recibido:</h3><p style='font-size:28px;'>{message}</p>\"\n","\n","        # Registrar uso de emojis\n","        for char in message:\n","            if char in emoji.EMOJI_DATA:\n","                self.emoji_usage_stats[char] += 1\n","\n","        # Habilitar botones de selección\n","        for card in self.options_display.children:\n","            card.children[1].disabled = False\n","\n","        # Deshabilitar envío para evitar spam\n","        self.send_button.disabled = True\n","\n","        # Guardar el mensaje para análisis\n","        self.communication_log.append({\n","            \"round\": self.current_round,\n","            \"target\": self.current_target,\n","            \"message\": message,\n","            \"options\": self.current_options.copy()\n","        })\n","\n","    def check_answer(self, selected_idx):\n","        selected_emoji = self.current_options[selected_idx]\n","        correct = (selected_emoji == self.current_target)\n","\n","        # Registrar éxito/fracaso para estadísticas\n","        message = self.communication_log[-1][\"message\"]\n","        for char in message:\n","            if char in emoji.EMOJI_DATA:\n","                self.emoji_success_rate[char][1] += 1  # incrementar total\n","                if correct:\n","                    self.emoji_success_rate[char][0] += 1  # incrementar éxitos\n","\n","        # Actualizar puntuación\n","        if correct:\n","            self.score += 1\n","            self.message_display.value = \"<h3 style='color:green;'>¡Correcto! Has identificado la imagen.</h3>\"\n","        else:\n","            self.message_display.value = f\"<h3 style='color:red;'>Incorrecto. La imagen correcta era: {self.current_target}</h3>\"\n","\n","        self.game_info.children[1].value = f\"Puntuación: {self.score}\"\n","\n","        # Actualizar el registro\n","        self.communication_log[-1][\"selected\"] = selected_emoji\n","        self.communication_log[-1][\"correct\"] = correct\n","\n","        # Deshabilitar botones para evitar selecciones múltiples\n","        for card in self.options_display.children:\n","            card.children[1].disabled = True\n","\n","        # Esperar un momento y pasar a la siguiente ronda\n","        import time\n","        time.sleep(2)\n","        self.next_round()\n","\n","    def end_game(self):\n","        message = f\"Juego terminado. Puntuación final: {self.score}/{self.max_rounds}\"\n","\n","        # Mostrar resultado final\n","        with self.target_display:\n","            clear_output(wait=True)\n","            display(HTML(f\"<h2 style='text-align:center;'>{message}</h2>\"))\n","\n","        # Guardar estadísticas\n","        self.game_history.append({\n","            \"date\": \"2025-02-20\",  # En una implementación real usaríamos la fecha actual\n","            \"score\": self.score,\n","            \"max_rounds\": self.max_rounds,\n","            \"communication_log\": self.communication_log,\n","            \"emoji_usage\": dict(self.emoji_usage_stats)\n","        })\n","\n","        self.save_game_history()\n","\n","        # Análisis con modelo de Hugging Face\n","        self.perform_semantic_analysis()\n","\n","    def get_all_emojis(self):\n","        all_emojis = []\n","        for category in self.image_categories.values():\n","            all_emojis.extend(category)\n","        return all_emojis\n","\n","    def load_game_history(self):\n","        try:\n","            if os.path.exists(\"emoji_game_history.json\"):\n","                with open(\"emoji_game_history.json\", \"r\", encoding=\"utf-8\") as f:\n","                    return json.load(f)\n","        except Exception as e:\n","            print(f\"Error cargando historial: {e}\")\n","        return []\n","\n","    def save_game_history(self):\n","        try:\n","            with open(\"emoji_game_history.json\", \"w\", encoding=\"utf-8\") as f:\n","                json.dump(self.game_history, f, ensure_ascii=False, indent=2)\n","            files.download(\"emoji_game_history.json\")\n","        except Exception as e:\n","            print(f\"Error guardando historial: {e}\")\n","\n","    def show_statistics(self, b=None):\n","        if not self.game_history and not self.communication_log:\n","            display(HTML(\"<p>No hay datos de juego disponibles.</p>\"))\n","            return\n","\n","        # Crear output para estadísticas\n","        stats_output = widgets.Output()\n","\n","        # Crear pestañas\n","        tab = widgets.Tab()\n","        tab_contents = [widgets.Output() for _ in range(4)]\n","        tab.children = tab_contents\n","        tab.set_title(0, 'Puntuaciones')\n","        tab.set_title(1, 'Uso de Emojis')\n","        tab.set_title(2, 'Patrones Emergentes')\n","        tab.set_title(3, 'Análisis Semántico')\n","\n","        # Pestaña de puntuaciones\n","        with tab_contents[0]:\n","            if self.game_history:\n","                scores = [game[\"score\"] for game in self.game_history]\n","                avg_score = sum(scores) / len(scores)\n","\n","                display(HTML(f\"<h3>Juegos jugados: {len(self.game_history)}</h3>\"))\n","                display(HTML(f\"<p>Puntuación media: {avg_score:.2f}</p>\"))\n","                display(HTML(f\"<p>Puntuación más alta: {max(scores)}</p>\"))\n","\n","                # Gráfico de puntuaciones\n","                plt.figure(figsize=(10, 6))\n","                plt.plot(range(1, len(scores) + 1), scores, marker='o', linestyle='-')\n","                plt.title('Evolución de Puntuaciones')\n","                plt.xlabel('Número de Juego')\n","                plt.ylabel('Puntuación')\n","                plt.grid(True)\n","                plt.show()\n","            else:\n","                display(HTML(\"<p>No hay suficientes datos históricos.</p>\"))\n","\n","        # Pestaña de uso de emojis\n","        with tab_contents[1]:\n","            # Combinar datos actuales e históricos\n","            all_emoji_usage = Counter(self.emoji_usage_stats)\n","            for game in self.game_history:\n","                for emoji_char, count in game.get(\"emoji_usage\", {}).items():\n","                    all_emoji_usage[emoji_char] += count\n","\n","            if all_emoji_usage:\n","                # Mostrar los emojis más usados\n","                display(HTML(\"<h3>Emojis más utilizados:</h3>\"))\n","\n","                # Crear tabla\n","                table_html = \"<table style='width:100%; border-collapse:collapse;'>\"\n","                table_html += \"<tr><th style='border:1px solid #ddd;padding:8px;'>Emoji</th>\"\n","                table_html += \"<th style='border:1px solid #ddd;padding:8px;'>Usos</th>\"\n","                table_html += \"<th style='border:1px solid #ddd;padding:8px;'>Tasa de Éxito</th></tr>\"\n","\n","                for emoji_char, count in all_emoji_usage.most_common(20):\n","                    success_rate = 0\n","                    if emoji_char in self.emoji_success_rate and self.emoji_success_rate[emoji_char][1] > 0:\n","                        success_rate = (self.emoji_success_rate[emoji_char][0] / self.emoji_success_rate[emoji_char][1]) * 100\n","\n","                    table_html += f\"<tr><td style='border:1px solid #ddd;padding:8px;font-size:20px;text-align:center;'>{emoji_char}</td>\"\n","                    table_html += f\"<td style='border:1px solid #ddd;padding:8px;text-align:center;'>{count}</td>\"\n","                    table_html += f\"<td style='border:1px solid #ddd;padding:8px;text-align:center;'>{success_rate:.1f}%</td></tr>\"\n","\n","                table_html += \"</table>\"\n","                display(HTML(table_html))\n","\n","                # Gráfico de barras con los emojis más usados\n","                top_emojis = dict(all_emoji_usage.most_common(10))\n","                plt.figure(figsize=(12, 6))\n","                plt.bar(top_emojis.keys(), top_emojis.values())\n","                plt.title('Top 10 Emojis Más Utilizados')\n","                plt.xlabel('Emoji')\n","                plt.ylabel('Frecuencia')\n","                plt.xticks(fontsize=16)  # Para que los emojis se vean bien\n","                plt.show()\n","            else:\n","                display(HTML(\"<p>No hay suficientes datos de uso de emojis.</p>\"))\n","\n","        # Pestaña de patrones emergentes\n","        with tab_contents[2]:\n","            display(HTML(\"<h3>Análisis de patrones emergentes:</h3>\"))\n","\n","            # Recopilar todos los mensajes\n","            all_messages = []\n","            for game in self.game_history:\n","                for entry in game.get(\"communication_log\", []):\n","                    all_messages.append((entry.get(\"message\", \"\"), entry.get(\"target\", \"\"), entry.get(\"correct\", False)))\n","\n","            if self.communication_log:\n","                for entry in self.communication_log:\n","                    all_messages.append((entry.get(\"message\", \"\"), entry.get(\"target\", \"\"), entry.get(\"correct\", False)))\n","\n","            if all_messages:\n","                # Analizar co-ocurrencias de emojis\n","                emoji_target_map = defaultdict(lambda: defaultdict(int))\n","                for message, target, _ in all_messages:\n","                    for char in message:\n","                        if char in emoji.EMOJI_DATA:\n","                            emoji_target_map[char][target] += 1\n","\n","                # Mostrar los mapeos más fuertes de emoji -> target\n","                display(HTML(\"<h4>Mapeos emergentes (emoji → concepto):</h4>\"))\n","\n","                # Crear tabla\n","                table_html = \"<table style='width:100%; border-collapse:collapse;'>\"\n","                table_html += \"<tr><th style='border:1px solid #ddd;padding:8px;'>Emoji</th>\"\n","                table_html += \"<th style='border:1px solid #ddd;padding:8px;'>Concepto más asociado</th>\"\n","                table_html += \"<th style='border:1px solid #ddd;padding:8px;'>Fuerza de asociación</th></tr>\"\n","\n","                for emoji_char, targets in sorted(emoji_target_map.items(),\n","                                               key=lambda x: max(x[1].values()) if x[1] else 0,\n","                                               reverse=True)[:15]:\n","                    if not targets:\n","                        continue\n","\n","                    # Encontrar el target más asociado\n","                    top_target = max(targets.items(), key=lambda x: x[1])\n","                    total_uses = sum(targets.values())\n","                    association_strength = (top_target[1] / total_uses) * 100\n","\n","                    table_html += f\"<tr><td style='border:1px solid #ddd;padding:8px;font-size:20px;text-align:center;'>{emoji_char}</td>\"\n","                    table_html += f\"<td style='border:1px solid #ddd;padding:8px;font-size:20px;text-align:center;'>{top_target[0]}</td>\"\n","                    table_html += f\"<td style='border:1px solid #ddd;padding:8px;text-align:center;'>{association_strength:.1f}%</td></tr>\"\n","\n","                table_html += \"</table>\"\n","                display(HTML(table_html))\n","\n","                # Análisis de secuencia de emojis\n","                display(HTML(\"<h4>Patrones de secuencia detectados:</h4>\"))\n","\n","                emoji_pairs = defaultdict(int)\n","                for message, _, _ in all_messages:\n","                    emoji_chars = [c for c in message if c in emoji.EMOJI_DATA]\n","                    if len(emoji_chars) > 1:\n","                        for i in range(len(emoji_chars)-1):\n","                            emoji_pairs[(emoji_chars[i], emoji_chars[i+1])] += 1\n","\n","                # Mostrar las secuencias más comunes\n","                if emoji_pairs:\n","                    top_pairs = sorted(emoji_pairs.items(), key=lambda x: x[1], reverse=True)[:10]\n","                    pair_labels = [f\"{pair[0][0]}{pair[0][1]}\" for pair in top_pairs]\n","                    pair_counts = [pair[1] for pair in top_pairs]\n","\n","                    plt.figure(figsize=(14, 6))\n","                    plt.bar(pair_labels, pair_counts)\n","                    plt.title('Secuencias de Emojis Más Comunes')\n","                    plt.xlabel('Par de Emojis')\n","                    plt.ylabel('Frecuencia')\n","                    plt.xticks(fontsize=16)\n","                    plt.show()\n","                else:\n","                    display(HTML(\"<p>No hay suficientes datos de secuencias.</p>\"))\n","            else:\n","                display(HTML(\"<p>No hay suficientes datos para analizar patrones emergentes.</p>\"))\n","\n","        # Pestaña de análisis semántico con Hugging Face\n","        with tab_contents[3]:\n","            display(HTML(\"<h3>Análisis Semántico con Modelos de Hugging Face:</h3>\"))\n","\n","            if hasattr(self, 'semantic_analysis_results'):\n","                # Mostrar mapa de calor de similitud\n","                if 'similarity_matrix' in self.semantic_analysis_results:\n","                    plt.figure(figsize=(12, 10))\n","                    sns.heatmap(\n","                        self.semantic_analysis_results['similarity_matrix'],\n","                        annot=True,\n","                        xticklabels=self.semantic_analysis_results['emoji_list'],\n","                        yticklabels=self.semantic_analysis_results['emoji_list'],\n","                        cmap=\"YlGnBu\"\n","                    )\n","                    plt.title('Mapa de Similitud Semántica entre Emojis')\n","                    plt.show()\n","\n","                # Mostrar clústeres\n","                if 'clusters' in self.semantic_analysis_results:\n","                    display(HTML(\"<h4>Grupos semánticos de emojis:</h4>\"))\n","\n","                    for i, cluster in enumerate(self.semantic_analysis_results['clusters']):\n","                        emojis_html = \" \".join([f\"<span style='font-size:24px;'>{e}</span>\" for e in cluster])\n","                        display(HTML(f\"<p><b>Grupo {i+1}:</b> {emojis_html}</p>\"))\n","\n","                # Mostrar análisis de sentimiento\n","                if 'sentiment_analysis' in self.semantic_analysis_results:\n","                    display(HTML(\"<h4>Análisis de Sentimiento por Categoría:</h4>\"))\n","\n","                    sentiment_data = self.semantic_analysis_results['sentiment_analysis']\n","                    categories = list(sentiment_data.keys())\n","                    sentiment_values = [sentiment_data[cat]['score'] for cat in categories]\n","\n","                    plt.figure(figsize=(10, 6))\n","                    bars = plt.bar(categories, sentiment_values, color=['skyblue' if val > 0 else 'lightcoral' for val in sentiment_values])\n","                    plt.title('Polaridad Emocional por Categoría')\n","                    plt.xlabel('Categoría')\n","                    plt.ylabel('Polaridad (-1 a 1)')\n","                    plt.ylim(-1, 1)\n","\n","                    # Añadir valores\n","                    for bar in bars:\n","                        height = bar.get_height()\n","                        plt.text(bar.get_x() + bar.get_width()/2., height,\n","                                f'{height:.2f}',\n","                                ha='center', va='bottom' if height > 0 else 'top')\n","\n","                    plt.show()\n","            else:\n","                display(HTML(\"<p>El análisis semántico no se ha realizado todavía. Completa al menos una ronda de juego.</p>\"))\n","\n","        # Mostrar el widget de pestañas\n","        display(tab)\n","\n","    def perform_semantic_analysis(self):\n","        \"\"\"Realiza análisis avanzado con modelos de Hugging Face\"\"\"\n","        print(\"Realizando análisis semántico con modelos de Hugging Face...\")\n","\n","        # Obtener todos los emojis usados\n","        used_emojis = [emoji for emoji, count in self.emoji_usage_stats.items() if count > 0]\n","        if not used_emojis:\n","            used_emojis = list(self.get_all_emojis())[:20]  # Usar algunos emojis por defecto\n","\n","        # 1. Análisis de similitud semántica\n","        emoji_descriptions = {\n","            emoji: f\"Emoji that represents {emoji} symbol\" for emoji in used_emojis\n","        }\n","\n","        # Obtener embeddings para las descripciones\n","        descriptions = list(emoji_descriptions.values())\n","        embeddings = get_embeddings(descriptions, self.tokenizer, self.model)\n","\n","        # Calcular matriz de similitud\n","        similarity_matrix = torch.nn.functional.cosine_similarity(\n","            embeddings.unsqueeze(1), embeddings.unsqueeze(0), dim=2\n","        ).numpy()\n","\n","        # 2. Análisis de clustering para agrupar emojis semánticamente similares\n","        from sklearn.cluster import KMeans\n","\n","        # Determinar número óptimo de clusters (aquí simplificado)\n","        num_clusters = min(5, len(used_emojis))\n","\n","        kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n","        clusters = kmeans.fit_predict(embeddings.numpy())\n","\n","        # Organizar emojis por cluster\n","        emoji_clusters = [[] for _ in range(num_clusters)]\n","        for i, emoji in enumerate(used_emojis):\n","            emoji_clusters[clusters[i]].append(emoji)\n","\n","        # 3. Análisis de sentimiento por categoría\n","        sentiment_results = {}\n","        for category, emoji_list in self.image_categories.items():\n","            emoji_text = \" \".join(emoji_list)\n","\n","            try:\n","                sentiment = self.sentiment_analyzer(emoji_text)[0]\n","                # Convertir a escala -1 a 1\n","                score = (int(sentiment['label'][0]) - 3) / 2\n","                sentiment_results[category] = {\n","                    'label': sentiment['label'],\n","                    'score': score\n","                }\n","            except Exception as e:\n","                sentiment_results[category] = {\n","                    'label': 'neutral',\n","                    'score': 0,\n","                    'error': str(e)\n","                }"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gc-Zzju8dnnn","executionInfo":{"status":"ok","timestamp":1740073573481,"user_tz":360,"elapsed":47830,"user":{"displayName":"Alan Mauricio Camargo Hernandez","userId":"09753390928466343821"}},"outputId":"05f1fc61-6622-49c6-8529-0aafb5981225"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting emoji\n","  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n","Collecting datasets\n","  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (7.7.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (6.17.1)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.6.10)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.13)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n","Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.0)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n","Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (24.0.1)\n","Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.2)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (75.1.0)\n","Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.50)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.5)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.7.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.5)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.21.1)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.3.6)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.3)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n","Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.2)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.1)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.2)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.23.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n","Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.22.3)\n","Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.24.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n","Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n","Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.3.2-py3-none-any.whl (485 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, jedi, emoji, dill, multiprocess, datasets\n","Successfully installed datasets-3.3.2 dill-0.3.8 emoji-2.14.1 jedi-0.19.2 multiprocess-0.70.16 xxhash-3.5.0\n"]}]},{"cell_type":"code","source":["!pip install transformers torch emoji"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mfYtgjtmF1k5","executionInfo":{"status":"ok","timestamp":1740084170034,"user_tz":360,"elapsed":120409,"user":{"displayName":"Alan Mauricio Camargo Hernandez","userId":"09753390928466343821"}},"outputId":"ee8616b5-c22a-45b5-fa2a-8ee86768a907"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n","Collecting emoji\n","  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, emoji, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed emoji-2.14.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"]}]},{"cell_type":"code","source":["import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from collections import defaultdict, Counter\n","import emoji\n","\n","class EmojiAgent:\n","    def __init__(self, name, learning_rate=0.1):\n","        self.name = name\n","        self.learning_rate = learning_rate\n","        # Mapeo interno de conceptos a emojis (probabilidades)\n","        self.concept_to_emoji_map = {}\n","        # Mapeo inverso de emojis a conceptos\n","        self.emoji_to_concept_map = {}\n","        # Historial de éxitos de comunicación\n","        self.success_history = []\n","\n","    def initialize_mappings(self, concepts, emoji_vocabulary):\n","        \"\"\"Inicializa los mapeos con probabilidades aleatorias\"\"\"\n","        for concept in concepts:\n","            self.concept_to_emoji_map[concept] = {\n","                e: 1.0/len(emoji_vocabulary) for e in emoji_vocabulary\n","            }\n","\n","        for emoji_char in emoji_vocabulary:\n","            self.emoji_to_concept_map[emoji_char] = {\n","                c: 1.0/len(concepts) for c in concepts\n","            }\n","\n","    def encode_concept(self, concept, num_emojis=3):\n","        \"\"\"Emisor: Codifica un concepto en una secuencia de emojis\"\"\"\n","        if concept not in self.concept_to_emoji_map:\n","            return \"❓\"\n","\n","        # Seleccionar emojis basados en las probabilidades actuales\n","        emoji_probs = self.concept_to_emoji_map[concept]\n","        emoji_chars = list(emoji_probs.keys())\n","        probabilities = list(emoji_probs.values())\n","\n","        # Normalizar probabilidades\n","        total = sum(probabilities)\n","        normalized_probs = [p/total for p in probabilities]\n","\n","        # Seleccionar emojis basados en las probabilidades\n","        selected_emojis = np.random.choice(\n","            emoji_chars,\n","            size=min(num_emojis, len(emoji_chars)),\n","            replace=False,\n","            p=normalized_probs\n","        )\n","\n","        return ''.join(selected_emojis)\n","\n","    def decode_message(self, message):\n","        \"\"\"Receptor: Interpreta un mensaje de emojis y devuelve el concepto más probable\"\"\"\n","        if not message:\n","            return None\n","\n","        # Calcular la probabilidad para cada concepto\n","        concept_scores = defaultdict(float)\n","\n","        for emoji_char in message:\n","            if emoji_char in self.emoji_to_concept_map:\n","                for concept, prob in self.emoji_to_concept_map[emoji_char].items():\n","                    concept_scores[concept] += prob\n","\n","        # Devolver el concepto con la puntuación más alta\n","        if not concept_scores:\n","            # print(list(self.emoji_to_concept_map.values())[0])\n","            return random.choice(list(list(self.emoji_to_concept_map.values())[0].keys()))\n","\n","        return max(concept_scores.items(), key=lambda x: x[1])[0]\n","\n","    def update_mappings(self, concept, message, success):\n","        \"\"\"Actualiza los mapeos internos basados en el éxito de la comunicación\"\"\"\n","        # Registrar el resultado\n","        self.success_history.append(success)\n","\n","        # Si fue exitoso, reforzar las asociaciones\n","        reward = self.learning_rate if success else -self.learning_rate/2\n","\n","        # Actualizar mapeo concepto -> emoji (para el emisor)\n","        if concept in self.concept_to_emoji_map:\n","            for emoji_char in message:\n","                if emoji_char in self.concept_to_emoji_map[concept]:\n","                    # Reforzar o debilitar la asociación\n","                    self.concept_to_emoji_map[concept][emoji_char] += reward\n","                    # Asegurar que queda en rango positivo\n","                    self.concept_to_emoji_map[concept][emoji_char] = max(0.01, self.concept_to_emoji_map[concept][emoji_char])\n","\n","        # Actualizar mapeo emoji -> concepto (para el receptor)\n","        for emoji_char in message:\n","            if emoji_char in self.emoji_to_concept_map:\n","                for c, prob in self.emoji_to_concept_map[emoji_char].items():\n","                    # Reforzar el concepto correcto, debilitar los demás\n","                    adjustment = reward if c == concept else -reward/3\n","                    self.emoji_to_concept_map[emoji_char][c] += adjustment\n","                    # Asegurar que queda en rango positivo\n","                    self.emoji_to_concept_map[emoji_char][c] = max(0.01, self.emoji_to_concept_map[emoji_char][c])\n","\n","    def get_success_rate(self, window=100):\n","        \"\"\"Calcula la tasa de éxito reciente\"\"\"\n","        if not self.success_history:\n","            return 0\n","\n","        recent = self.success_history[-min(window, len(self.success_history)):]\n","        return sum(recent) / len(recent)\n","\n","    def get_strongest_mappings(self, top_n=5):\n","        \"\"\"Devuelve los mapeos más fuertes\"\"\"\n","        strongest_mappings = {}\n","\n","        for concept, emoji_map in self.concept_to_emoji_map.items():\n","            # Ordenar emojis por fuerza de asociación\n","            sorted_emojis = sorted(emoji_map.items(), key=lambda x: x[1], reverse=True)[:top_n]\n","            strongest_mappings[concept] = sorted_emojis\n","\n","        return strongest_mappings\n","\n","\n","class EmojiLanguageSimulation:\n","    def __init__(self):\n","        # Categorías e imágenes (representadas como palabras conceptuales)\n","        self.categories = {\n","            \"animales\": [\"perro\", \"gato\", \"tigre\", \"león\", \"vaca\", \"cerdo\", \"rana\", \"pájaro\", \"zorro\", \"tortuga\"],\n","            \"comida\": [\"manzana\", \"pizza\", \"hamburguesa\", \"helado\", \"pastel\", \"cerveza\", \"pollo\", \"aguacate\", \"fresa\", \"huevo\"],\n","            \"lugares\": [\"casa\", \"edificio\", \"montaña\", \"playa\", \"volcán\", \"monumento\", \"paisaje\", \"ciudad\", \"camping\", \"isla\"],\n","            \"transporte\": [\"coche\", \"avión\", \"tren\", \"barco\", \"helicóptero\", \"bicicleta\", \"moto\", \"autobús\", \"tractor\", \"nave espacial\"],\n","            \"clima\": [\"sol\", \"lluvia\", \"nieve\", \"arcoiris\", \"relámpago\", \"tornado\", \"nube\", \"niebla\", \"ola\", \"fuego\"]\n","        }\n","\n","        # Mapeo de conceptos a emojis (para visualización)\n","        self.concept_emoji_visualization = {\n","            \"perro\": \"🐶\", \"gato\": \"🐱\", \"tigre\": \"🐯\", \"león\": \"🦁\", \"vaca\": \"🐮\",\n","            \"cerdo\": \"🐷\", \"rana\": \"🐸\", \"pájaro\": \"🐦\", \"zorro\": \"🦊\", \"tortuga\": \"🐢\",\n","            \"manzana\": \"🍎\", \"pizza\": \"🍕\", \"hamburguesa\": \"🍔\", \"helado\": \"🍦\", \"pastel\": \"🍰\",\n","            \"cerveza\": \"🍺\", \"pollo\": \"🍗\", \"aguacate\": \"🥑\", \"fresa\": \"🍓\", \"huevo\": \"🍳\",\n","            \"casa\": \"🏠\", \"edificio\": \"🏢\", \"montaña\": \"⛰️\", \"playa\": \"🏖️\", \"volcán\": \"🌋\",\n","            \"monumento\": \"🏛️\", \"paisaje\": \"🏞️\", \"ciudad\": \"🌆\", \"camping\": \"🏕️\", \"isla\": \"🏝️\",\n","            \"coche\": \"🚗\", \"avión\": \"✈️\", \"tren\": \"🚂\", \"barco\": \"🚢\", \"helicóptero\": \"🚁\",\n","            \"bicicleta\": \"🚲\", \"moto\": \"🛵\", \"autobús\": \"🚌\", \"tractor\": \"🚜\", \"nave espacial\": \"🛸\",\n","            \"sol\": \"☀️\", \"lluvia\": \"🌧️\", \"nieve\": \"❄️\", \"arcoiris\": \"🌈\", \"relámpago\": \"⚡\",\n","            \"tornado\": \"🌪️\", \"nube\": \"☁️\", \"niebla\": \"🌫️\", \"ola\": \"🌊\", \"fuego\": \"🔥\"\n","        }\n","\n","        # Lista plana de todos los conceptos\n","        self.all_concepts = []\n","        for category in self.categories.values():\n","            self.all_concepts.extend(category)\n","\n","        # Vocabulario de emojis disponible para los agentes\n","        # Incluye más emojis que los de visualización para permitir creatividad\n","        self.emoji_vocabulary = [\n","            \"😀\", \"😂\", \"😍\", \"🤔\", \"😎\", \"😢\", \"😡\", \"🙄\", \"🤯\", \"😴\",\n","            \"👍\", \"👎\", \"👏\", \"🙌\", \"👀\", \"👂\", \"👃\", \"👄\", \"💪\", \"🦾\",\n","            \"❤️\", \"💔\", \"💯\", \"💢\", \"💫\", \"💥\", \"💦\", \"💨\", \"👑\", \"🎓\",\n","            \"🌍\", \"🌎\", \"🌏\", \"🌕\", \"🌟\", \"🔥\", \"💧\", \"🌈\", \"☁️\", \"⚡\",\n","            \"🏠\", \"🏢\", \"🏭\", \"🏥\", \"🏫\", \"🏰\", \"⛺\", \"🌁\", \"🌃\", \"🌄\",\n","            \"🚗\", \"🚕\", \"🚙\", \"🚌\", \"🚒\", \"🚑\", \"🚓\", \"✈️\", \"🚀\", \"⛵\",\n","            \"🐶\", \"🐱\", \"🐭\", \"🐹\", \"🐰\", \"🦊\", \"🐻\", \"🐼\", \"🐨\", \"🦁\",\n","            \"🍏\", \"🍎\", \"🍐\", \"🍊\", \"🍋\", \"🍌\", \"🍉\", \"🍇\", \"🍓\", \"🍒\",\n","            \"⚽\", \"🏀\", \"🏈\", \"⚾\", \"🎾\", \"🏐\", \"🎱\", \"🏓\", \"🎯\", \"🎮\",\n","            \"1️⃣\", \"2️⃣\", \"3️⃣\", \"4️⃣\", \"5️⃣\", \"6️⃣\", \"7️⃣\", \"8️⃣\", \"9️⃣\", \"0️⃣\",\n","            \"⬆️\", \"↗️\", \"➡️\", \"↘️\", \"⬇️\", \"↙️\", \"⬅️\", \"↖️\", \"↕️\", \"↔️\"\n","        ]\n","\n","        # Crear agentes\n","        self.emisor = EmojiAgent(\"Emisor\")\n","        self.receptor = EmojiAgent(\"Receptor\")\n","\n","        # Inicializar mapeos\n","        self.emisor.initialize_mappings(self.all_concepts, self.emoji_vocabulary)\n","        self.receptor.initialize_mappings(self.all_concepts, self.emoji_vocabulary)\n","\n","        # Estadísticas de la simulación\n","        self.communication_log = []\n","        self.success_rates = []\n","        self.current_round = 0\n","\n","    def run_simulation(self, num_rounds=1000, verbose=False):\n","        \"\"\"Ejecuta la simulación por un número determinado de rondas\"\"\"\n","        print(f\"Iniciando simulación de {num_rounds} rondas de comunicación...\")\n","\n","        for i in range(num_rounds):\n","            self.current_round = i+1\n","\n","            # Seleccionar un concepto aleatorio\n","            target_concept = random.choice(self.all_concepts)\n","            target_emoji = self.concept_emoji_visualization[target_concept]\n","\n","            # Emisor codifica el concepto en un mensaje de emojis\n","            message = self.emisor.encode_concept(target_concept)\n","\n","            # Receptor decodifica el mensaje\n","            decoded_concept = self.receptor.decode_message(message)\n","\n","            # Verificar éxito\n","            success = (decoded_concept == target_concept)\n","\n","            # Registrar la comunicación\n","            self.communication_log.append({\n","                \"round\": self.current_round,\n","                \"target_concept\": target_concept,\n","                \"target_emoji\": target_emoji,\n","                \"message\": message,\n","                \"decoded_concept\": decoded_concept,\n","                \"success\": success\n","            })\n","\n","            # Actualizar mapeos de ambos agentes\n","            self.emisor.update_mappings(target_concept, message, success)\n","            self.receptor.update_mappings(target_concept, message, success)\n","\n","            # Calcular y guardar tasa de éxito actual\n","            if i % 10 == 0:\n","                success_rate = sum([log[\"success\"] for log in self.communication_log[-100:]]) / min(100, len(self.communication_log))\n","                self.success_rates.append(success_rate)\n","\n","                if verbose and i % 100 == 0:\n","                    print(f\"Ronda {self.current_round}: Tasa de éxito: {success_rate:.2f}\")\n","                    print(f\"  Concepto: {target_concept} ({target_emoji})\")\n","                    print(f\"  Mensaje: {message}\")\n","                    print(f\"  Interpretación: {decoded_concept}\")\n","                    print(f\"  Éxito: {'✓' if success else '✗'}\")\n","                    print()\n","\n","        print(f\"Simulación completada. Tasa de éxito final: {self.success_rates[-1]:.2f}\")\n","\n","    def visualize_results(self):\n","        \"\"\"Visualiza los resultados de la simulación\"\"\"\n","        # 1. Gráfico de evolución de la tasa de éxito\n","        plt.figure(figsize=(12, 6))\n","        x_values = [i*10 for i in range(len(self.success_rates))]\n","        plt.plot(x_values, self.success_rates, marker='o', linestyle='-', markersize=4)\n","        plt.title('Evolución de la Tasa de Éxito en la Comunicación')\n","        plt.xlabel('Ronda')\n","        plt.ylabel('Tasa de Éxito (ventana de 100 rondas)')\n","        plt.grid(True)\n","        plt.show()\n","\n","        # 2. Mostrar los mapeos emergentes más fuertes\n","        print(\"\\n=== LENGUAJE EMERGENTE DESARROLLADO POR LOS AGENTES ===\\n\")\n","\n","        strongest_mappings = self.emisor.get_strongest_mappings(top_n=3)\n","\n","        # Organizar por categoría\n","        for category, concepts in self.categories.items():\n","            print(f\"\\n=== CATEGORÍA: {category.upper()} ===\")\n","\n","            for concept in concepts:\n","                if concept in strongest_mappings:\n","                    concept_emoji = self.concept_emoji_visualization[concept]\n","                    print(f\"\\n{concept} {concept_emoji}:\")\n","\n","                    for emoji, strength in strongest_mappings[concept]:\n","                        percentage = strength * 100 / sum([s for _, s in strongest_mappings[concept]])\n","                        print(f\"  {emoji} - {percentage:.1f}% asociación\")\n","\n","        # 3. Analizar patrones emergentes\n","        self.analyze_emergent_patterns()\n","\n","    def analyze_emergent_patterns(self):\n","        \"\"\"Analiza patrones emergentes en el lenguaje desarrollado\"\"\"\n","        print(\"\\n=== ANÁLISIS DE PATRONES EMERGENTES ===\\n\")\n","\n","        # 1. Analizar los últimos 200 mensajes exitosos\n","        successful_logs = [log for log in self.communication_log[-500:] if log[\"success\"]]\n","        if len(successful_logs) < 10:\n","            print(\"No hay suficientes comunicaciones exitosas para analizar patrones.\")\n","            return\n","\n","        # 2. Contador de emojis por categoría\n","        category_emoji_usage = defaultdict(Counter)\n","\n","        for log in successful_logs:\n","            concept = log[\"target_concept\"]\n","            message = log[\"message\"]\n","\n","            # Encontrar a qué categoría pertenece el concepto\n","            for category, concepts in self.categories.items():\n","                if concept in concepts:\n","                    # Contar uso de emojis para esta categoría\n","                    for emoji_char in message:\n","                        category_emoji_usage[category][emoji_char] += 1\n","\n","        # 3. Mostrar emojis más utilizados por categoría\n","        print(\"Emojis más utilizados por categoría (en comunicaciones exitosas):\")\n","        for category, counter in category_emoji_usage.items():\n","            print(f\"\\n{category.upper()}:\")\n","            top_emojis = counter.most_common(5)\n","            if top_emojis:\n","                for emoji, count in top_emojis:\n","                    total = sum(counter.values())\n","                    percentage = (count / total) * 100\n","                    print(f\"  {emoji}: {percentage:.1f}% ({count}/{total})\")\n","            else:\n","                print(\"  No hay datos suficientes\")\n","\n","        # 4. Análisis de combinaciones de emojis\n","        print(\"\\nCombinaciones de emojis emergentes:\")\n","        emoji_combinations = Counter()\n","\n","        for log in successful_logs:\n","            if len(log[\"message\"]) >= 2:\n","                emoji_combinations[log[\"message\"]] += 1\n","\n","        common_combinations = emoji_combinations.most_common(10)\n","        if common_combinations:\n","            for combo, count in common_combinations:\n","                print(f\"  {combo}: usado {count} veces\")\n","\n","                # Buscar para qué conceptos se usó esta combinación\n","                concepts_for_combo = []\n","                for log in successful_logs:\n","                    if log[\"message\"] == combo:\n","                        concepts_for_combo.append(log[\"target_concept\"])\n","\n","                if concepts_for_combo:\n","                    concept_counter = Counter(concepts_for_combo)\n","                    top_concepts = concept_counter.most_common(3)\n","                    concept_str = \", \".join([f\"{c} ({self.concept_emoji_visualization[c]}): {n}\" for c, n in top_concepts])\n","                    print(f\"    → Usado principalmente para: {concept_str}\")\n","        else:\n","            print(\"  No hay combinaciones recurrentes\")\n","\n","    def test_communication(self, num_tests=500):\n","        \"\"\"Prueba la efectividad del lenguaje emergente con nuevos ejemplos\"\"\"\n","        print(\"\\n=== PRUEBA DEL LENGUAJE EMERGENTE ===\\n\")\n","\n","        successes = 0\n","\n","        for i in range(num_tests):\n","            # Seleccionar un concepto aleatorio\n","            target_concept = random.choice(self.all_concepts)\n","            target_emoji = self.concept_emoji_visualization[target_concept]\n","\n","            # Emisor codifica el concepto\n","            message = self.emisor.encode_concept(target_concept)\n","\n","            # Receptor decodifica el mensaje\n","            decoded_concept = self.receptor.decode_message(message)\n","            decoded_emoji = self.concept_emoji_visualization.get(decoded_concept, \"❓\")\n","\n","            # Verificar éxito\n","            success = (decoded_concept == target_concept)\n","            if success:\n","                successes += 1\n","\n","            # Mostrar resultados\n","            print(f\"Test {i+1}:\")\n","            print(f\"  Concepto objetivo: {target_concept} {target_emoji}\")\n","            print(f\"  Mensaje emitido: {message}\")\n","            print(f\"  Concepto interpretado: {decoded_concept} {decoded_emoji}\")\n","            print(f\"  Resultado: {'✓ ÉXITO' if success else '✗ ERROR'}\")\n","            print()\n","\n","        success_rate = (successes / num_tests) * 100\n","        print(f\"Tasa de éxito en las pruebas: {success_rate:.1f}%\")\n","\n","\n","# Ejecutar una simulación completa\n","def run_emoji_language_experiment():\n","    # Crear y ejecutar la simulación\n","    sim = EmojiLanguageSimulation()\n","\n","    # Fase de entrenamiento - los agentes desarrollan un lenguaje\n","    sim.run_simulation(num_rounds=2000, verbose=False)\n","\n","    # Visualizar resultados y analizar el lenguaje emergente\n","    sim.visualize_results()\n","\n","    # Probar la comunicación con nuevos ejemplos\n","    sim.test_communication(num_tests=15)\n","\n","    return sim\n","\n","# Esta función principal ejecuta el experimento completo\n","if __name__ == \"__main__\":\n","    simulation = run_emoji_language_experiment()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"id":"uH8F9gA0e0Lq","executionInfo":{"status":"error","timestamp":1740084030374,"user_tz":360,"elapsed":319,"user":{"displayName":"Alan Mauricio Camargo Hernandez","userId":"09753390928466343821"}},"outputId":"8fa1178b-c12a-42d9-9cc7-c5f7467a4012"},"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'emoji'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-f8557f8f1b9c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0memoji\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mEmojiAgent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'emoji'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":[],"metadata":{"id":"kABu0JcJg_rJ"},"execution_count":null,"outputs":[]}]}